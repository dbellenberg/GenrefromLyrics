{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, DataCollatorWithPadding\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "import pytorch_lightning as pl\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_lyrics(lyrics):\n",
    "    # Remove strings enclosed in brackets []\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n",
    "    \n",
    "    # Remove substrings starting with a backslash \\\n",
    "    lyrics = re.sub(r'\\\\[^\\s]*', '', lyrics)\n",
    "\n",
    "    # Remove newline characters \\n\n",
    "    lyrics = re.sub(r'\\n', ' ', lyrics)\n",
    "    \n",
    "    # Remove single quotes '\n",
    "    lyrics = re.sub(r\"'\", '', lyrics)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    lyrics = lyrics.strip()\n",
    "\n",
    "    # Strip the string and ensure only one space between words\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics.strip())\n",
    "\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/work/cleaned_df/df_cleaned_engl.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "#convert to dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#add word count\n",
    "df['word_count'] = df['lyrics'].progress_apply(lambda x: len(x.split()))\n",
    "\n",
    "df = df[(df['word_count'] < 5000) & (df['word_count'] > 25)]\n",
    "df = df[(df['year'] >= 1960) & (df['year'] <= 2023)]\n",
    "\n",
    "#drop columns of subset\n",
    "df.drop(columns=[\"title\",'artist', 'year',\"id\",\"language\",\"word_count\"], inplace=True)\n",
    "\n",
    "# apply strip_lyrics (re)\n",
    "df['lyrics'] = df['lyrics'].progress_apply(lambda x: strip_lyrics(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing for Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_bert(dataframe):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "    def tokenize_song(song):\n",
    "        tokenized = tokenizer.encode(song, max_length=512, truncation=True, padding='max_length')\n",
    "        return tokenized\n",
    "\n",
    "    # Pass both song and index using lambda function\n",
    "    tokenized = dataframe['lyrics'].reset_index().progress_apply(lambda x: tokenize_song((x['lyrics'])), axis=1)\n",
    "    return tokenized\n",
    "\n",
    "# Example usage\n",
    "tokenized_lyrics = tokenize_with_bert(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving tokenized data (& labels) to .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tokenized lyrics and labels\n",
    "with open('tokenized_lyrics.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenized_lyrics, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#label encode \"tag\" column\n",
    "le = LabelEncoder()\n",
    "\n",
    "#creatze new df for label encoding\n",
    "df_enc = df.copy()\n",
    "\n",
    "df_enc['tag'] = le.fit_transform(df_enc['tag'])\n",
    "\n",
    "with open('labels_le.pickle', 'wb') as handle:\n",
    "    pickle.dump(df_enc['tag'], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
