{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ucloud/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/utils.py:757: UserWarning: Expected 4 arguments for function <function predict_genre at 0x7f778a68a3b0>, received 3.\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/utils.py:761: UserWarning: Expected at least 4 arguments for function <function predict_genre at 0x7f778a68a3b0>, received 3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "Running on local URL:  http://127.0.0.1:7864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 65\u001b[0m\n\u001b[1;32m     52\u001b[0m description \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m<img src=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m alt=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpotify Logo\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     54\u001b[0m iface \u001b[39m=\u001b[39m gr\u001b[39m.\u001b[39mInterface(\n\u001b[1;32m     55\u001b[0m     fn\u001b[39m=\u001b[39mpredict_genre,\n\u001b[1;32m     56\u001b[0m     inputs\u001b[39m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m     description\u001b[39m=\u001b[39mdescription\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m iface\u001b[39m.\u001b[39;49mlaunch(debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, share\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gradio/blocks.py:1834\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[0;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[1;32m   1832\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1833\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_url \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1834\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_url \u001b[39m=\u001b[39m networking\u001b[39m.\u001b[39;49msetup_tunnel(\n\u001b[1;32m   1835\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserver_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserver_port, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshare_token\n\u001b[1;32m   1836\u001b[0m         )\n\u001b[1;32m   1837\u001b[0m     \u001b[39mprint\u001b[39m(strings\u001b[39m.\u001b[39men[\u001b[39m\"\u001b[39m\u001b[39mSHARE_LINK_DISPLAY\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare_url))\n\u001b[1;32m   1838\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (quiet):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/gradio/networking.py:169\u001b[0m, in \u001b[0;36msetup_tunnel\u001b[0;34m(local_host, local_port, share_token)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msetup_tunnel\u001b[39m(local_host: \u001b[39mstr\u001b[39m, local_port: \u001b[39mint\u001b[39m, share_token: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(GRADIO_API_SERVER)\n\u001b[1;32m    170\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m    171\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import joblib\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "# Load your trained Word2Vec model\n",
    "w2v_model = Word2Vec.load('/work/NLP_Project/GenreFromLyricsShared/Word2VecModels/original_w2v.model')\n",
    "\n",
    "def preprocess(lyrics):\n",
    "    #stop = stopwords.words('english')\n",
    "    lyrics = re.sub('\\n', ' ', lyrics)\n",
    "    lyrics = re.sub('\\[.*?\\]', '', lyrics)\n",
    "    lyrics = re.sub('\\\\[^\\s]*', '', lyrics)\n",
    "    lyrics = re.sub(\"'\", '', lyrics)\n",
    "    lyrics = lyrics.strip()\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics)\n",
    "    lyrics = re.sub('['+string.punctuation+']', '', lyrics)\n",
    "    lyrics = lyrics.lower()\n",
    "    lyrics = re.sub('chorus', '', lyrics)\n",
    "    lyrics = re.sub('verse', '', lyrics)\n",
    "    #lyrics = ' '.join([word for word in lyrics.split() if word not in stop])\n",
    "    tokens = nltk.word_tokenize(lyrics)\n",
    "\n",
    "    # Use Word2Vec model to generate word vectors and then calculate the mean vector\n",
    "    vector = np.mean([w2v_model.wv[word] for word in tokens if word in w2v_model.wv.key_to_index], axis=0)\n",
    "    return vector\n",
    "\n",
    "def predict_genre(Artist, Title, Lyrics, File):\n",
    "    # Preprocess the lyrics\n",
    "    vector = preprocess(lyrics)\n",
    "\n",
    "    # Reshape the vector to 2D array as the model.predict expects 2D array\n",
    "    vector = vector.reshape(1, -1)\n",
    "\n",
    "    # Load the trained Random Forest Classifier\n",
    "    clf = joblib.load('/work/NLP_Project/GenreFromLyricsShared/random_forest.sav')\n",
    "\n",
    "    # Get the probabilities of each class\n",
    "    probabilities = clf.predict_proba(vector)[0]\n",
    "\n",
    "    # Map each probability with the corresponding genre\n",
    "    genres = clf.classes_\n",
    "    result = {genre: prob for genre, prob in zip(genres, probabilities)}\n",
    "\n",
    "    return result\n",
    "\n",
    "description = '<img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\">'\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_genre,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Artist Here...'),\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Title Here...'),\n",
    "        gr.inputs.Textbox(lines=4, placeholder='Lyrics Here...'),\n",
    "        #gr.inputs.File()\n",
    "    ],\n",
    "    outputs=gr.outputs.Label(label=\"Genre Suggestion\"),\n",
    "    description=description\n",
    ")\n",
    "iface.launch(debug=True, share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  90 out of 100 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country': 0.05, 'pop': 0.47, 'rap': 0.19, 'rb': 0.07, 'rock': 0.22}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_genre(\"X\", \"X\", \"hello\", \"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:27: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/inputs.py:30: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  super().__init__(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/gradio/outputs.py:200: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  super().__init__(num_top_classes=num_top_classes, type=type, label=label)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://62b589753eec286911.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://62b589753eec286911.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7865 <> https://62b589753eec286911.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import gradio as gr\n",
    "from transformers import BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {'input_ids': torch.as_tensor(self.encodings.iloc[idx])}\n",
    "        item['labels'] = torch.as_tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "class LyricsClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=5): #@RIES TRY \"bert-large-uncased\" with the A100\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(self.hparams.model_name,\n",
    "                                                                  num_labels=self.hparams.num_labels)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\",compute_on_step=False, num_classes=num_labels)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        return self.bert(input_ids, labels=labels)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(batch['input_ids'], batch['labels'])\n",
    "        loss = outputs.loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(batch['input_ids'], batch['labels'])\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        correct = (predicted == batch['labels']).sum().item()\n",
    "        accuracy = correct / len(batch['labels'])\n",
    "        self.log('val_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=1e-5)\n",
    "\n",
    "model = LyricsClassifier.load_from_checkpoint(checkpoint_path=\"/work/NLP_Project/GenreFromLyricsShared/epoch=1-step=145040.ckpt\", map_location=torch.device('cpu'))\n",
    "\n",
    "def strip_lyrics(lyrics):\n",
    "    # Remove strings enclosed in brackets []\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n",
    "    \n",
    "    # Remove substrings starting with a backslash \\\n",
    "    lyrics = re.sub(r'\\\\[^\\s]*', '', lyrics)\n",
    "\n",
    "    # Remove newline characters \\n\n",
    "    lyrics = re.sub(r'\\n', ' ', lyrics)\n",
    "    \n",
    "    # Remove single quotes '\n",
    "    lyrics = re.sub(r\"'\", '', lyrics)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    lyrics = lyrics.strip()\n",
    "\n",
    "    # Strip the string and ensure only one space between words\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics.strip())\n",
    "\n",
    "    return lyrics\n",
    "\n",
    "def predict_genre(Artist, Title, Lyrics):\n",
    "    lyrics = strip_lyrics(lyrics)  # Preprocess the lyrics\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    inputs = tokenizer(lyrics, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    input_ids = inputs['input_ids'].to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "    probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "    probabilities = probabilities.cpu().numpy()\n",
    "\n",
    "    label_map = {0: 'Country', 1: 'Pop', 2: 'Rap', 3: 'R&B', 4: 'Rock'}\n",
    "    \n",
    "    probabilities_dict = {label_map[i]: float(prob) for i, prob in enumerate(probabilities[0])}  # convert numpy.float32 to float\n",
    "\n",
    "    return probabilities_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "description = '<img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\">'\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_genre,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Artist Here...'),\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Title Here...'),\n",
    "        gr.inputs.Textbox(lines=4, placeholder='Lyrics Here...'),\n",
    "        #gr.inputs.File()\n",
    "    ],\n",
    "    outputs=gr.outputs.Label(num_top_classes=5, label=\"Genre Suggestion\"),\n",
    "    description=description\n",
    ")\n",
    "iface.launch(debug=True, share=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strip_lyrics() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHank, Beugard, Big Sur Y\u001b[39m\u001b[39m'\u001b[39m\u001b[39mall know how this - go, you know All eyes on me, OG Roll up in the club and shit (is that right?) All eyes on me All eyes on me Ay you know what? I bet you got it twisted, you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt know who to trust So many player-hatin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m - tryna sound like us Say they ready for the funk, but I don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt think they knowin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Straight to the depths of Hell is where them cowards goin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m Well, are you still down? Holla when you see me And let these devils be sorry for the day they finally freed me I got a caravan of - every time we ride Hittin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m - up when we pass by Until I die, live the life of a boss player, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcause even when I\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm high F- with me and get crossed later, the futures in my eyes \u001b[39m\u001b[39m'\u001b[39m\u001b[39mCause all I want is cash and thangs A five-double-oh Benz, flauntin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m flashy rings Uhh, - pursue me like a dream Been known to disappear before your eyes just like a dope fiend It seems, my main thing was to be major paid The game sharper than a - razor blade Say money bring - bring lies One - gettin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m jealous and - die Depend on me like the first and fifteenth They might hold me for a second, but these punks won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt get me We got four niggas in low riders and ski masks Screamin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, Thug Life every time they pass, all eyes on me Live the life of a thug - until the day I die Live the life of a boss player All eyes on me All eyes on me Live the life of a thug - until the day I die Live the life of a boss player \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcause even gettin\u001b[39m\u001b[39m'\u001b[39m\u001b[39m high\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m#strip lyrics\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m text_stripped \u001b[39m=\u001b[39m strip_lyrics(\u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m, text)\n\u001b[1;32m      7\u001b[0m probabilities \u001b[39m=\u001b[39m predict_genre(text_stripped)\n",
      "\u001b[0;31mTypeError\u001b[0m: strip_lyrics() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"Hank, Beugard, Big Sur Y'all know how this - go, you know All eyes on me, OG Roll up in the club and shit (is that right?) All eyes on me All eyes on me Ay you know what? I bet you got it twisted, you don't know who to trust So many player-hatin' - tryna sound like us Say they ready for the funk, but I don't think they knowin' Straight to the depths of Hell is where them cowards goin' Well, are you still down? Holla when you see me And let these devils be sorry for the day they finally freed me I got a caravan of - every time we ride Hittin' - up when we pass by Until I die, live the life of a boss player, 'cause even when I'm high F- with me and get crossed later, the futures in my eyes 'Cause all I want is cash and thangs A five-double-oh Benz, flauntin' flashy rings Uhh, - pursue me like a dream Been known to disappear before your eyes just like a dope fiend It seems, my main thing was to be major paid The game sharper than a - razor blade Say money bring - bring lies One - gettin' jealous and - die Depend on me like the first and fifteenth They might hold me for a second, but these punks won't get me We got four niggas in low riders and ski masks Screamin', Thug Life every time they pass, all eyes on me Live the life of a thug - until the day I die Live the life of a boss player All eyes on me All eyes on me Live the life of a thug - until the day I die Live the life of a boss player 'cause even gettin' high\"\n",
    "\n",
    "#strip lyrics\n",
    "text_stripped = strip_lyrics(\"hi\", \"hi\", text)\n",
    "\n",
    "probabilities = predict_genre(text_stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Country': 0.0007394675,\n",
       " 'Pop': 0.24420594,\n",
       " 'Rap': 0.737701,\n",
       " 'R&B': 0.0054926835,\n",
       " 'Rock': 0.011860887}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
