{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT MODEL LIVE TESTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizerFast, DataCollatorWithPadding\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_lyrics(lyrics):\n",
    "    # Remove strings enclosed in brackets []\n",
    "    lyrics = re.sub(r'\\[.*?\\]', '', lyrics)\n",
    "    \n",
    "    # Remove substrings starting with a backslash \\\n",
    "    lyrics = re.sub(r'\\\\[^\\s]*', '', lyrics)\n",
    "\n",
    "    # Remove newline characters \\n\n",
    "    lyrics = re.sub(r'\\n', ' ', lyrics)\n",
    "    \n",
    "    # Remove single quotes '\n",
    "    lyrics = re.sub(r\"'\", '', lyrics)\n",
    "    \n",
    "    # Remove leading and trailing whitespaces\n",
    "    lyrics = lyrics.strip()\n",
    "\n",
    "    # Strip the string and ensure only one space between words\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics.strip())\n",
    "\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {'input_ids': torch.as_tensor(self.encodings.iloc[idx])}\n",
    "        item['labels'] = torch.as_tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)\n",
    "\n",
    "class LyricsClassifier(pl.LightningModule):\n",
    "    def __init__(self, model_name='bert-base-uncased', num_labels=5): #@RIES TRY \"bert-large-uncased\" with the A100\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(self.hparams.model_name,\n",
    "                                                                  num_labels=self.hparams.num_labels)\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\",compute_on_step=False, num_classes=num_labels)\n",
    "\n",
    "    def forward(self, input_ids, labels=None):\n",
    "        return self.bert(input_ids, labels=labels)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(batch['input_ids'], batch['labels'])\n",
    "        loss = outputs.loss\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.forward(batch['input_ids'], batch['labels'])\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        correct = (predicted == batch['labels']).sum().item()\n",
    "        accuracy = correct / len(batch['labels'])\n",
    "        self.log('val_accuracy', accuracy, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return accuracy\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = LyricsClassifier.load_from_checkpoint(checkpoint_path=\"/Users/davidbellenberg/github_projects/GenrefromLyrics/notebooks/BERT/epoch=1-step=145040.ckpt\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def predict_genre(lyrics):\n",
    "    # Use the same tokenizer model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    # Preprocess the lyrics\n",
    "    inputs = tokenizer(lyrics, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    # Only use input_ids for the model\n",
    "    input_ids = inputs['input_ids'].to(model.device)\n",
    "    # Predict with the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    # Compute softmax to get probabilities\n",
    "    probabilities = F.softmax(outputs.logits, dim=-1)\n",
    "    # Move probabilities to cpu in numpy format to make it more interpretable\n",
    "    probabilities = probabilities.cpu().numpy()\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text = \"Hank, Beugard, Big Sur Y'all know how this - go, you know All eyes on me, OG Roll up in the club and shit (is that right?) All eyes on me All eyes on me Ay you know what? I bet you got it twisted, you don't know who to trust So many player-hatin' - tryna sound like us Say they ready for the funk, but I don't think they knowin' Straight to the depths of Hell is where them cowards goin' Well, are you still down? Holla when you see me And let these devils be sorry for the day they finally freed me I got a caravan of - every time we ride Hittin' - up when we pass by Until I die, live the life of a boss player, 'cause even when I'm high F- with me and get crossed later, the futures in my eyes 'Cause all I want is cash and thangs A five-double-oh Benz, flauntin' flashy rings Uhh, - pursue me like a dream Been known to disappear before your eyes just like a dope fiend It seems, my main thing was to be major paid The game sharper than a - razor blade Say money bring - bring lies One - gettin' jealous and - die Depend on me like the first and fifteenth They might hold me for a second, but these punks won't get me We got four niggas in low riders and ski masks Screamin', Thug Life every time they pass, all eyes on me Live the life of a thug - until the day I die Live the life of a boss player All eyes on me All eyes on me Live the life of a thug - until the day I die Live the life of a boss player 'cause even gettin' high\"\n",
    "\n",
    "#strip lyrics\n",
    "text_stripped = strip_lyrics(text)\n",
    "\n",
    "probabilities = predict_genre(text_stripped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gradio-client>=0.2.4\n",
      "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting altair>=4.2.0\n",
      "  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx\n",
      "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (0.14.1)\n",
      "Collecting python-multipart\n",
      "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (6.0)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: pandas in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (2.0.1)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pygments>=2.12.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (2.15.1)\n",
      "Collecting mdit-py-plugins<=0.3.3\n",
      "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading orjson-3.8.14-cp38-cp38-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (239 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiofiles\n",
      "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: requests in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (2.29.0)\n",
      "Collecting markdown-it-py[linkify]>=2.0.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting semantic-version\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: pillow in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (9.5.0)\n",
      "Collecting websockets>=10.0\n",
      "  Downloading websockets-11.0.3-cp38-cp38-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (4.5.0)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (1.10.7)\n",
      "Requirement already satisfied: matplotlib in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (1.24.3)\n",
      "Requirement already satisfied: aiohttp in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio) (3.8.4)\n",
      "Collecting toolz\n",
      "  Using cached toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: packaging in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio-client>=0.2.4->gradio) (23.1)\n",
      "Requirement already satisfied: fsspec in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from gradio-client>=0.2.4->gradio) (2023.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub>=0.13.0->gradio) (4.65.0)\n",
      "Requirement already satisfied: filelock in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from huggingface-hub>=0.13.0->gradio) (3.12.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py<3,>=1\n",
      "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->gradio) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->gradio) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from pandas->gradio) (2023.3)\n",
      "Collecting h11>=0.8\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: click>=7.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (3.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from aiohttp->gradio) (1.9.2)\n",
      "Collecting starlette<0.28.0,>=0.27.0\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from httpx->gradio) (2022.12.7)\n",
      "Collecting httpcore<0.18.0,>=0.15.0\n",
      "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from httpx->gradio) (3.4)\n",
      "Collecting sniffio\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (4.39.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (1.0.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (5.12.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from matplotlib->gradio) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from requests->gradio) (1.26.15)\n",
      "Collecting anyio<5.0,>=3.0\n",
      "  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.15.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/davidbellenberg/anaconda3/envs/nlp_env/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4693 sha256=2cff121ddff263dac3893e526df1eb948f555ed6d1ed64dbf6060bfdedd9e7e5\n",
      "  Stored in directory: /Users/davidbellenberg/Library/Caches/pip/wheels/ff/5b/59/913b443e7369dc04b61f607a746b6f7d83fb65e2e19fcc958d\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, toolz, sniffio, semantic-version, python-multipart, orjson, mdurl, h11, aiofiles, uvicorn, markdown-it-py, linkify-it-py, anyio, starlette, mdit-py-plugins, httpcore, altair, httpx, fastapi, gradio-client, gradio\n",
      "Successfully installed aiofiles-23.1.0 altair-5.0.1 anyio-3.6.2 fastapi-0.95.2 ffmpy-0.3.0 gradio-3.32.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 linkify-it-py-2.0.2 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 orjson-3.8.14 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 sniffio-1.3.0 starlette-0.27.0 toolz-0.12.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def predict_genre(Artist, Title, Lyrics, File):\n",
    "    # Preprocess the lyrics\n",
    "    vector = preprocess(lyrics)\n",
    "\n",
    "    # Reshape the vector to 2D array as the model.predict expects 2D array\n",
    "    vector = vector.reshape(1, -1)\n",
    "\n",
    "    # Load the trained Random Forest Classifier\n",
    "    clf = joblib.load('/work/NLP_Project/GenreFromLyricsShared/random_forest.sav')\n",
    "\n",
    "    # Get the probabilities of each class\n",
    "    probabilities = clf.predict_proba(vector)[0]\n",
    "\n",
    "    # Map each probability with the corresponding genre\n",
    "    genres = clf.classes_\n",
    "    result = {genre: prob for genre, prob in zip(genres, probabilities)}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "description = '<img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\">'\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_genre,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Artist Here...'),\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Title Here...'),\n",
    "        gr.inputs.Textbox(lines=4, placeholder='Lyrics Here...'),\n",
    "        #gr.inputs.File()\n",
    "    ],\n",
    "    outputs=gr.outputs.Label(label=\"Genre Suggestion\"),\n",
    "    description=description\n",
    ")\n",
    "iface.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
