{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import gc\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/work/NLP_Project/word2vec.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics_word_count</th>\n",
       "      <th>tokenized_lyrics</th>\n",
       "      <th>word2vec_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>killa cam killa cam cam killa cam killa cam k...</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "      <td>[-1.0416342, -1.8244686, -0.28164017, 1.004815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>yeah hah yeah rocafella we invite you to so...</td>\n",
       "      <td>3</td>\n",
       "      <td>548</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, we, invite, you, ...</td>\n",
       "      <td>[-0.071794294, -1.3259815, -0.83557093, 0.0142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>maybe cause im eatin and these bastards fiend ...</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>[maybe, cause, im, eatin, and, these, bastards...</td>\n",
       "      <td>[-0.5561948, -1.3328351, -0.75972176, 0.155423...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>ugh killa baby kanye this that 1970s heron ...</td>\n",
       "      <td>5</td>\n",
       "      <td>760</td>\n",
       "      <td>[ugh, killa, baby, kanye, this, that, 1970s, h...</td>\n",
       "      <td>[-0.68215144, -1.4285321, -0.82841796, 0.45750...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>so they ask me young boy what you gon do the ...</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "      <td>[so, they, ask, me, young, boy, what, you, gon...</td>\n",
       "      <td>[-0.64928126, -1.543321, -0.9033364, 0.4230063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913399</th>\n",
       "      <td>Everything Is Alright Now</td>\n",
       "      <td>pop</td>\n",
       "      <td>Chuck Bernard</td>\n",
       "      <td>2013</td>\n",
       "      <td>everything is alright now oh yes baby everythi...</td>\n",
       "      <td>7882838</td>\n",
       "      <td>63</td>\n",
       "      <td>[everything, is, alright, now, oh, yes, baby, ...</td>\n",
       "      <td>[0.11393027, -0.5848491, -1.2231293, -0.729186...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913401</th>\n",
       "      <td>White Lies</td>\n",
       "      <td>pop</td>\n",
       "      <td>ElementD</td>\n",
       "      <td>2019</td>\n",
       "      <td>half truth and half you didnt we say were thr...</td>\n",
       "      <td>7882840</td>\n",
       "      <td>171</td>\n",
       "      <td>[half, truth, and, half, you, didnt, we, say, ...</td>\n",
       "      <td>[-0.23599629, -2.0092504, -1.1099375, -0.07128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913403</th>\n",
       "      <td>Ocean</td>\n",
       "      <td>pop</td>\n",
       "      <td>Effemar</td>\n",
       "      <td>2022</td>\n",
       "      <td>dance for me now keeping yourself moving your...</td>\n",
       "      <td>7882842</td>\n",
       "      <td>166</td>\n",
       "      <td>[dance, for, me, now, keeping, yourself, movin...</td>\n",
       "      <td>[-0.6133733, -0.9017366, -0.86565405, -0.94078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913406</th>\n",
       "      <td>Raise Our Hands</td>\n",
       "      <td>pop</td>\n",
       "      <td>Culture Code, Pag &amp; Mylo</td>\n",
       "      <td>2016</td>\n",
       "      <td>here our purpose feels alive we are more than...</td>\n",
       "      <td>7882845</td>\n",
       "      <td>184</td>\n",
       "      <td>[here, our, purpose, feels, alive, we, are, mo...</td>\n",
       "      <td>[-0.13819346, -1.3463497, -0.6037392, -0.07637...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913409</th>\n",
       "      <td>New Number</td>\n",
       "      <td>country</td>\n",
       "      <td>Alana Springsteen</td>\n",
       "      <td>2022</td>\n",
       "      <td>you need a new number one that aint burned in...</td>\n",
       "      <td>7882848</td>\n",
       "      <td>293</td>\n",
       "      <td>[you, need, a, new, number, one, that, aint, b...</td>\n",
       "      <td>[-1.1301076, -1.3281808, -1.6745925, 0.3468972...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3315185 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title      tag                    artist  year   \n",
       "0                        Killa Cam      rap                   Cam'ron  2004  \\\n",
       "1                       Can I Live      rap                     JAY-Z  1996   \n",
       "2                Forgive Me Father      rap                  Fabolous  2003   \n",
       "3                     Down and Out      rap                   Cam'ron  2004   \n",
       "4                           Fly In      rap                 Lil Wayne  2005   \n",
       "...                            ...      ...                       ...   ...   \n",
       "5913399  Everything Is Alright Now      pop             Chuck Bernard  2013   \n",
       "5913401                 White Lies      pop                  ElementD  2019   \n",
       "5913403                      Ocean      pop                   Effemar  2022   \n",
       "5913406            Raise Our Hands      pop  Culture Code, Pag & Mylo  2016   \n",
       "5913409                 New Number  country         Alana Springsteen  2022   \n",
       "\n",
       "                                                    lyrics       id   \n",
       "0         killa cam killa cam cam killa cam killa cam k...        1  \\\n",
       "1           yeah hah yeah rocafella we invite you to so...        3   \n",
       "2        maybe cause im eatin and these bastards fiend ...        4   \n",
       "3           ugh killa baby kanye this that 1970s heron ...        5   \n",
       "4         so they ask me young boy what you gon do the ...        6   \n",
       "...                                                    ...      ...   \n",
       "5913399  everything is alright now oh yes baby everythi...  7882838   \n",
       "5913401   half truth and half you didnt we say were thr...  7882840   \n",
       "5913403   dance for me now keeping yourself moving your...  7882842   \n",
       "5913406   here our purpose feels alive we are more than...  7882845   \n",
       "5913409   you need a new number one that aint burned in...  7882848   \n",
       "\n",
       "         lyrics_word_count                                   tokenized_lyrics   \n",
       "0                      762  [killa, cam, killa, cam, cam, killa, cam, kill...  \\\n",
       "1                      548  [yeah, hah, yeah, rocafella, we, invite, you, ...   \n",
       "2                      574  [maybe, cause, im, eatin, and, these, bastards...   \n",
       "3                      760  [ugh, killa, baby, kanye, this, that, 1970s, h...   \n",
       "4                      432  [so, they, ask, me, young, boy, what, you, gon...   \n",
       "...                    ...                                                ...   \n",
       "5913399                 63  [everything, is, alright, now, oh, yes, baby, ...   \n",
       "5913401                171  [half, truth, and, half, you, didnt, we, say, ...   \n",
       "5913403                166  [dance, for, me, now, keeping, yourself, movin...   \n",
       "5913406                184  [here, our, purpose, feels, alive, we, are, mo...   \n",
       "5913409                293  [you, need, a, new, number, one, that, aint, b...   \n",
       "\n",
       "                                           word2vec_lyrics  \n",
       "0        [-1.0416342, -1.8244686, -0.28164017, 1.004815...  \n",
       "1        [-0.071794294, -1.3259815, -0.83557093, 0.0142...  \n",
       "2        [-0.5561948, -1.3328351, -0.75972176, 0.155423...  \n",
       "3        [-0.68215144, -1.4285321, -0.82841796, 0.45750...  \n",
       "4        [-0.64928126, -1.543321, -0.9033364, 0.4230063...  \n",
       "...                                                    ...  \n",
       "5913399  [0.11393027, -0.5848491, -1.2231293, -0.729186...  \n",
       "5913401  [-0.23599629, -2.0092504, -1.1099375, -0.07128...  \n",
       "5913403  [-0.6133733, -0.9017366, -0.86565405, -0.94078...  \n",
       "5913406  [-0.13819346, -1.3463497, -0.6037392, -0.07637...  \n",
       "5913409  [-1.1301076, -1.3281808, -1.6745925, 0.3468972...  \n",
       "\n",
       "[3315185 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3315185, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['word2vec_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3314995, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:  4.0min remaining:  1.5min\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:  5.0min finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    2.3s remaining:    0.8s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    2.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    2.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.48      0.04      0.08     12678\n",
      "         pop       0.60      0.89      0.72    215348\n",
      "         rap       0.86      0.83      0.84    149475\n",
      "          rb       0.44      0.05      0.09     23801\n",
      "        rock       0.60      0.18      0.28     95947\n",
      "\n",
      "    accuracy                           0.67    497249\n",
      "   macro avg       0.60      0.40      0.40    497249\n",
      "weighted avg       0.67      0.67      0.62    497249\n",
      "\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.48      0.04      0.07     12677\n",
      "         pop       0.60      0.89      0.72    215348\n",
      "         rap       0.86      0.83      0.84    149476\n",
      "          rb       0.46      0.05      0.09     23802\n",
      "        rock       0.60      0.18      0.27     95947\n",
      "\n",
      "    accuracy                           0.67    497250\n",
      "   macro avg       0.60      0.40      0.40    497250\n",
      "weighted avg       0.67      0.67      0.62    497250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Create the classifier\n",
    "clf = RandomForestClassifier(n_jobs=31, verbose=3, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model on the train data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test and validation sets\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100\n",
      "building tree 2 of 100\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:  6.8min remaining:  2.5min\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:  8.6min finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    2.4s remaining:    0.9s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    2.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.46      0.09      0.15     12678\n",
      "         pop       0.62      0.83      0.71    215348\n",
      "         rap       0.84      0.84      0.84    149475\n",
      "          rb       0.39      0.09      0.15     23801\n",
      "        rock       0.54      0.28      0.37     95947\n",
      "\n",
      "    accuracy                           0.67    497249\n",
      "   macro avg       0.57      0.43      0.44    497249\n",
      "weighted avg       0.66      0.67      0.64    497249\n",
      "\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.46      0.08      0.14     12677\n",
      "         pop       0.62      0.83      0.71    215348\n",
      "         rap       0.84      0.84      0.84    149476\n",
      "          rb       0.40      0.10      0.16     23802\n",
      "        rock       0.54      0.28      0.37     95947\n",
      "\n",
      "    accuracy                           0.67    497250\n",
      "   macro avg       0.57      0.43      0.44    497250\n",
      "weighted avg       0.66      0.67      0.64    497250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Initialize the Random Over Sampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create the classifier\n",
    "clf = RandomForestClassifier(n_jobs=31, verbose=3, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model on the train data\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test and validation sets\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 100building tree 2 of 100\n",
      "\n",
      "building tree 3 of 100\n",
      "building tree 4 of 100\n",
      "building tree 5 of 100\n",
      "building tree 6 of 100\n",
      "building tree 7 of 100\n",
      "building tree 8 of 100\n",
      "building tree 9 of 100\n",
      "building tree 10 of 100\n",
      "building tree 11 of 100\n",
      "building tree 12 of 100\n",
      "building tree 13 of 100\n",
      "building tree 14 of 100\n",
      "building tree 15 of 100\n",
      "building tree 16 of 100\n",
      "building tree 17 of 100\n",
      "building tree 18 of 100\n",
      "building tree 19 of 100\n",
      "building tree 20 of 100\n",
      "building tree 21 of 100\n",
      "building tree 22 of 100\n",
      "building tree 23 of 100\n",
      "building tree 24 of 100\n",
      "building tree 25 of 100\n",
      "building tree 26 of 100\n",
      "building tree 27 of 100\n",
      "building tree 28 of 100\n",
      "building tree 29 of 100\n",
      "building tree 30 of 100\n",
      "building tree 31 of 100\n",
      "building tree 32 of 100\n",
      "building tree 33 of 100\n",
      "building tree 34 of 100\n",
      "building tree 35 of 100\n",
      "building tree 36 of 100\n",
      "building tree 37 of 100\n",
      "building tree 38 of 100\n",
      "building tree 39 of 100\n",
      "building tree 40 of 100\n",
      "building tree 41 of 100\n",
      "building tree 42 of 100\n",
      "building tree 43 of 100\n",
      "building tree 44 of 100\n",
      "building tree 45 of 100\n",
      "building tree 46 of 100\n",
      "building tree 47 of 100\n",
      "building tree 48 of 100\n",
      "building tree 49 of 100\n",
      "building tree 50 of 100\n",
      "building tree 51 of 100\n",
      "building tree 52 of 100\n",
      "building tree 53 of 100\n",
      "building tree 54 of 100\n",
      "building tree 55 of 100\n",
      "building tree 56 of 100\n",
      "building tree 57 of 100\n",
      "building tree 58 of 100\n",
      "building tree 59 of 100\n",
      "building tree 60 of 100\n",
      "building tree 61 of 100\n",
      "building tree 62 of 100\n",
      "building tree 63 of 100\n",
      "building tree 64 of 100\n",
      "building tree 65 of 100\n",
      "building tree 66 of 100\n",
      "building tree 67 of 100\n",
      "building tree 68 of 100\n",
      "building tree 69 of 100\n",
      "building tree 70 of 100\n",
      "building tree 71 of 100\n",
      "building tree 72 of 100\n",
      "building tree 73 of 100\n",
      "building tree 74 of 100\n",
      "building tree 75 of 100\n",
      "building tree 76 of 100\n",
      "building tree 77 of 100\n",
      "building tree 78 of 100\n",
      "building tree 79 of 100\n",
      "building tree 80 of 100\n",
      "building tree 81 of 100\n",
      "building tree 82 of 100\n",
      "building tree 83 of 100\n",
      "building tree 84 of 100\n",
      "building tree 85 of 100\n",
      "building tree 86 of 100\n",
      "building tree 87 of 100\n",
      "building tree 88 of 100\n",
      "building tree 89 of 100\n",
      "building tree 90 of 100\n",
      "building tree 91 of 100\n",
      "building tree 92 of 100\n",
      "building tree 93 of 100\n",
      "building tree 94 of 100\n",
      "building tree 95 of 100\n",
      "building tree 96 of 100\n",
      "building tree 97 of 100\n",
      "building tree 98 of 100\n",
      "building tree 99 of 100\n",
      "building tree 100 of 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:   20.3s remaining:    7.5s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:   25.2s finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    1.2s remaining:    0.5s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  73 out of 100 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=31)]: Done 100 out of 100 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.10      0.64      0.18     12678\n",
      "         pop       0.67      0.25      0.37    215348\n",
      "         rap       0.87      0.77      0.81    149475\n",
      "          rb       0.15      0.57      0.24     23801\n",
      "        rock       0.41      0.49      0.45     95947\n",
      "\n",
      "    accuracy                           0.48    497249\n",
      "   macro avg       0.44      0.54      0.41    497249\n",
      "weighted avg       0.64      0.48      0.51    497249\n",
      "\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.10      0.64      0.18     12677\n",
      "         pop       0.67      0.26      0.37    215348\n",
      "         rap       0.87      0.77      0.82    149476\n",
      "          rb       0.15      0.57      0.24     23802\n",
      "        rock       0.41      0.49      0.45     95947\n",
      "\n",
      "    accuracy                           0.48    497250\n",
      "   macro avg       0.44      0.54      0.41    497250\n",
      "weighted avg       0.64      0.48      0.51    497250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Initialize the Random Over Sampler\n",
    "ros = RandomUnderSampler(random_state=42)\n",
    "\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create the classifier\n",
    "clf = RandomForestClassifier(n_jobs=31, verbose=3, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model on the train data\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test and validation sets\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 250building tree 2 of 250\n",
      "building tree 3 of 250\n",
      "\n",
      "building tree 4 of 250\n",
      "building tree 5 of 250\n",
      "building tree 6 of 250\n",
      "building tree 7 of 250\n",
      "building tree 8 of 250\n",
      "building tree 9 of 250\n",
      "building tree 10 of 250\n",
      "building tree 11 of 250\n",
      "building tree 12 of 250\n",
      "building tree 13 of 250\n",
      "building tree 14 of 250\n",
      "building tree 15 of 250\n",
      "building tree 16 of 250\n",
      "building tree 17 of 250\n",
      "building tree 18 of 250\n",
      "building tree 19 of 250\n",
      "building tree 20 of 250\n",
      "building tree 21 of 250\n",
      "building tree 22 of 250\n",
      "building tree 23 of 250\n",
      "building tree 24 of 250\n",
      "building tree 25 of 250\n",
      "building tree 26 of 250\n",
      "building tree 27 of 250\n",
      "building tree 28 of 250\n",
      "building tree 29 of 250\n",
      "building tree 30 of 250\n",
      "building tree 31 of 250\n",
      "building tree 32 of 250\n",
      "building tree 33 of 250\n",
      "building tree 34 of 250\n",
      "building tree 35 of 250\n",
      "building tree 36 of 250\n",
      "building tree 37 of 250\n",
      "building tree 38 of 250\n",
      "building tree 39 of 250\n",
      "building tree 40 of 250\n",
      "building tree 41 of 250\n",
      "building tree 42 of 250\n",
      "building tree 43 of 250\n",
      "building tree 44 of 250\n",
      "building tree 45 of 250\n",
      "building tree 46 of 250\n",
      "building tree 47 of 250\n",
      "building tree 48 of 250\n",
      "building tree 49 of 250\n",
      "building tree 50 of 250\n",
      "building tree 51 of 250\n",
      "building tree 52 of 250\n",
      "building tree 53 of 250\n",
      "building tree 54 of 250\n",
      "building tree 55 of 250\n",
      "building tree 56 of 250\n",
      "building tree 57 of 250\n",
      "building tree 58 of 250\n",
      "building tree 59 of 250\n",
      "building tree 60 of 250\n",
      "building tree 61 of 250\n",
      "building tree 62 of 250\n",
      "building tree 63 of 250\n",
      "building tree 64 of 250\n",
      "building tree 65 of 250\n",
      "building tree 66 of 250\n",
      "building tree 67 of 250\n",
      "building tree 68 of 250\n",
      "building tree 69 of 250\n",
      "building tree 70 of 250\n",
      "building tree 71 of 250\n",
      "building tree 72 of 250\n",
      "building tree 73 of 250\n",
      "building tree 74 of 250\n",
      "building tree 75 of 250\n",
      "building tree 76 of 250\n",
      "building tree 77 of 250\n",
      "building tree 78 of 250\n",
      "building tree 79 of 250\n",
      "building tree 80 of 250\n",
      "building tree 81 of 250\n",
      "building tree 82 of 250\n",
      "building tree 83 of 250\n",
      "building tree 84 of 250\n",
      "building tree 85 of 250\n",
      "building tree 86 of 250\n",
      "building tree 87 of 250\n",
      "building tree 88 of 250\n",
      "building tree 89 of 250\n",
      "building tree 90 of 250\n",
      "building tree 91 of 250\n",
      "building tree 92 of 250\n",
      "building tree 93 of 250\n",
      "building tree 94 of 250\n",
      "building tree 95 of 250\n",
      "building tree 96 of 250\n",
      "building tree 97 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done  66 tasks      | elapsed:  6.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 98 of 250\n",
      "building tree 99 of 250\n",
      "building tree 100 of 250\n",
      "building tree 101 of 250\n",
      "building tree 102 of 250\n",
      "building tree 103 of 250\n",
      "building tree 104 of 250\n",
      "building tree 105 of 250\n",
      "building tree 106 of 250\n",
      "building tree 107 of 250\n",
      "building tree 108 of 250\n",
      "building tree 109 of 250\n",
      "building tree 110 of 250\n",
      "building tree 111 of 250\n",
      "building tree 112 of 250\n",
      "building tree 113 of 250\n",
      "building tree 114 of 250\n",
      "building tree 115 of 250\n",
      "building tree 116 of 250\n",
      "building tree 117 of 250\n",
      "building tree 118 of 250\n",
      "building tree 119 of 250\n",
      "building tree 120 of 250\n",
      "building tree 121 of 250\n",
      "building tree 122 of 250\n",
      "building tree 123 of 250\n",
      "building tree 124 of 250\n",
      "building tree 125 of 250\n",
      "building tree 126 of 250\n",
      "building tree 127 of 250\n",
      "building tree 128 of 250\n",
      "building tree 129 of 250\n",
      "building tree 130 of 250\n",
      "building tree 131 of 250\n",
      "building tree 132 of 250\n",
      "building tree 133 of 250\n",
      "building tree 134 of 250\n",
      "building tree 135 of 250\n",
      "building tree 136 of 250\n",
      "building tree 137 of 250\n",
      "building tree 138 of 250\n",
      "building tree 139 of 250\n",
      "building tree 140 of 250\n",
      "building tree 141 of 250\n",
      "building tree 142 of 250\n",
      "building tree 143 of 250\n",
      "building tree 144 of 250\n",
      "building tree 145 of 250\n",
      "building tree 146 of 250\n",
      "building tree 147 of 250\n",
      "building tree 148 of 250\n",
      "building tree 149 of 250\n",
      "building tree 150 of 250\n",
      "building tree 151 of 250\n",
      "building tree 152 of 250\n",
      "building tree 153 of 250\n",
      "building tree 154 of 250\n",
      "building tree 155 of 250\n",
      "building tree 156 of 250\n",
      "building tree 157 of 250\n",
      "building tree 158 of 250\n",
      "building tree 159 of 250\n",
      "building tree 160 of 250\n",
      "building tree 161 of 250\n",
      "building tree 162 of 250\n",
      "building tree 163 of 250\n",
      "building tree 164 of 250\n",
      "building tree 165 of 250\n",
      "building tree 166 of 250\n",
      "building tree 167 of 250\n",
      "building tree 168 of 250\n",
      "building tree 169 of 250\n",
      "building tree 170 of 250\n",
      "building tree 171 of 250\n",
      "building tree 172 of 250\n",
      "building tree 173 of 250\n",
      "building tree 174 of 250\n",
      "building tree 175 of 250\n",
      "building tree 176 of 250\n",
      "building tree 177 of 250\n",
      "building tree 178 of 250\n",
      "building tree 179 of 250\n",
      "building tree 180 of 250\n",
      "building tree 181 of 250\n",
      "building tree 182 of 250\n",
      "building tree 183 of 250\n",
      "building tree 184 of 250\n",
      "building tree 185 of 250\n",
      "building tree 186 of 250\n",
      "building tree 187 of 250\n",
      "building tree 188 of 250\n",
      "building tree 189 of 250\n",
      "building tree 190 of 250\n",
      "building tree 191 of 250\n",
      "building tree 192 of 250\n",
      "building tree 193 of 250\n",
      "building tree 194 of 250\n",
      "building tree 195 of 250\n",
      "building tree 196 of 250\n",
      "building tree 197 of 250\n",
      "building tree 198 of 250\n",
      "building tree 199 of 250\n",
      "building tree 200 of 250\n",
      "building tree 201 of 250\n",
      "building tree 202 of 250\n",
      "building tree 203 of 250\n",
      "building tree 204 of 250\n",
      "building tree 205 of 250\n",
      "building tree 206 of 250\n",
      "building tree 207 of 250\n",
      "building tree 208 of 250\n",
      "building tree 209 of 250\n",
      "building tree 210 of 250\n",
      "building tree 211 of 250\n",
      "building tree 212 of 250\n",
      "building tree 213 of 250\n",
      "building tree 214 of 250\n",
      "building tree 215 of 250\n",
      "building tree 216 of 250\n",
      "building tree 217 of 250\n",
      "building tree 218 of 250\n",
      "building tree 219 of 250\n",
      "building tree 220 of 250\n",
      "building tree 221 of 250\n",
      "building tree 222 of 250\n",
      "building tree 223 of 250\n",
      "building tree 224 of 250\n",
      "building tree 225 of 250\n",
      "building tree 226 of 250\n",
      "building tree 227 of 250\n",
      "building tree 228 of 250\n",
      "building tree 229 of 250\n",
      "building tree 230 of 250\n",
      "building tree 231 of 250\n",
      "building tree 232 of 250\n",
      "building tree 233 of 250\n",
      "building tree 234 of 250\n",
      "building tree 235 of 250\n",
      "building tree 236 of 250\n",
      "building tree 237 of 250\n",
      "building tree 238 of 250\n",
      "building tree 239 of 250\n",
      "building tree 240 of 250\n",
      "building tree 241 of 250\n",
      "building tree 242 of 250\n",
      "building tree 243 of 250\n",
      "building tree 244 of 250\n",
      "building tree 245 of 250\n",
      "building tree 246 of 250\n",
      "building tree 247 of 250\n",
      "building tree 248 of 250\n",
      "building tree 249 of 250\n",
      "building tree 250 of 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Done 250 out of 250 | elapsed: 20.2min finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  66 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=31)]: Done 250 out of 250 | elapsed:    7.0s finished\n",
      "[Parallel(n_jobs=31)]: Using backend ThreadingBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=31)]: Done  66 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=31)]: Done 250 out of 250 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.48      0.09      0.15     12678\n",
      "         pop       0.62      0.84      0.71    215348\n",
      "         rap       0.84      0.84      0.84    149475\n",
      "          rb       0.40      0.09      0.15     23801\n",
      "        rock       0.56      0.27      0.36     95947\n",
      "\n",
      "    accuracy                           0.68    497249\n",
      "   macro avg       0.58      0.43      0.44    497249\n",
      "weighted avg       0.66      0.68      0.64    497249\n",
      "\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.46      0.08      0.14     12677\n",
      "         pop       0.62      0.84      0.71    215348\n",
      "         rap       0.84      0.84      0.84    149476\n",
      "          rb       0.41      0.10      0.16     23802\n",
      "        rock       0.56      0.27      0.36     95947\n",
      "\n",
      "    accuracy                           0.68    497250\n",
      "   macro avg       0.58      0.43      0.44    497250\n",
      "weighted avg       0.66      0.68      0.64    497250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Initialize the Random Over Sampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Create the classifier\n",
    "clf = RandomForestClassifier(n_estimators=250, n_jobs=31, verbose=3, class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model on the train data\n",
    "clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predict on the test and validation sets\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_val_pred = clf.predict(X_val)\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "72516/72516 [==============================] - 177s 2ms/step - loss: 0.8179 - accuracy: 0.6744 - val_loss: 0.8076 - val_accuracy: 0.6779\n",
      "Epoch 2/5\n",
      "72516/72516 [==============================] - 174s 2ms/step - loss: 0.8015 - accuracy: 0.6794 - val_loss: 0.8008 - val_accuracy: 0.6784\n",
      "Epoch 3/5\n",
      "72516/72516 [==============================] - 175s 2ms/step - loss: 0.7975 - accuracy: 0.6808 - val_loss: 0.7971 - val_accuracy: 0.6813\n",
      "Epoch 4/5\n",
      "72516/72516 [==============================] - 172s 2ms/step - loss: 0.7952 - accuracy: 0.6817 - val_loss: 0.7935 - val_accuracy: 0.6821\n",
      "Epoch 5/5\n",
      "72516/72516 [==============================] - 171s 2ms/step - loss: 0.7938 - accuracy: 0.6820 - val_loss: 0.7918 - val_accuracy: 0.6822\n",
      "72516/72516 [==============================] - 72s 987us/step - loss: 0.7900 - accuracy: 0.6830\n",
      "15540/15540 [==============================] - 16s 1ms/step - loss: 0.7918 - accuracy: 0.6822\n",
      "Training accuracy: [0.7900110483169556, 0.6830406188964844]\n",
      "Validation accuracy: [0.791759729385376, 0.6822302937507629]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(5, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = to_categorical(encoder.fit_transform(y_train))\n",
    "y_val_encoded = to_categorical(encoder.transform(y_val))\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_val, y_val_encoded), epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = model.evaluate(X_train, y_train_encoded)\n",
    "val_accuracy = model.evaluate(X_val, y_val_encoded)\n",
    "\n",
    "print(f'Training accuracy: {train_accuracy}')\n",
    "print(f'Validation accuracy: {val_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "157025/157025 [==============================] - 373s 2ms/step - loss: 1.0305 - accuracy: 0.5754 - val_loss: 1.0533 - val_accuracy: 0.5013\n",
      "Epoch 2/5\n",
      "157025/157025 [==============================] - 370s 2ms/step - loss: 1.0125 - accuracy: 0.5822 - val_loss: 1.0842 - val_accuracy: 0.4890\n",
      "Epoch 3/5\n",
      "157025/157025 [==============================] - 366s 2ms/step - loss: 1.0084 - accuracy: 0.5842 - val_loss: 1.0601 - val_accuracy: 0.4925\n",
      "Epoch 4/5\n",
      "157025/157025 [==============================] - 367s 2ms/step - loss: 1.0060 - accuracy: 0.5850 - val_loss: 1.1194 - val_accuracy: 0.4632\n",
      "Epoch 5/5\n",
      "157025/157025 [==============================] - 364s 2ms/step - loss: 1.0045 - accuracy: 0.5855 - val_loss: 1.0662 - val_accuracy: 0.5078\n",
      "15540/15540 [==============================] - 14s 877us/step\n",
      "\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Initialize the Random Over Sampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convert labels to categorical\n",
    "encoder = LabelEncoder()\n",
    "y_train_res_encoded = to_categorical(encoder.fit_transform(y_train_res))\n",
    "y_val_encoded = to_categorical(encoder.transform(y_val))  # We do not oversample the validation set\n",
    "\n",
    "# Define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train_res.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(5, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train_res, y_train_res_encoded, validation_data=(X_val, y_val_encoded), epochs=5, batch_size=32)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert these probabilities to class labels\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15540/15540 [==============================] - 14s 912us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.11      0.75      0.19     12678\n",
      "         pop       0.69      0.28      0.39    215348\n",
      "         rap       0.87      0.82      0.84    149475\n",
      "          rb       0.18      0.56      0.27     23801\n",
      "        rock       0.45      0.50      0.47     95947\n",
      "\n",
      "    accuracy                           0.51    497249\n",
      "   macro avg       0.46      0.58      0.43    497249\n",
      "weighted avg       0.66      0.51      0.53    497249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##SCOND NN - OVERSAMPLING - NO OVERSAMPLINGWAS BETTER \n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_encoded = to_categorical(encoder.transform(y_test))\n",
    "\n",
    "# The model's predictions are probabilities for each class. To use them in the classification report,\n",
    "# we need to convert these probabilities to class labels. We can do this by taking the class with the highest probability.\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Similarly, convert y_test_encoded back to labels\n",
    "y_test_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_labels, y_test_pred_classes, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "72516/72516 [==============================] - 194s 3ms/step - loss: 0.8789 - accuracy: 0.6577 - val_loss: 0.8409 - val_accuracy: 0.6688\n",
      "Epoch 2/20\n",
      "72516/72516 [==============================] - 191s 3ms/step - loss: 0.8616 - accuracy: 0.6622 - val_loss: 0.8306 - val_accuracy: 0.6656\n",
      "Epoch 3/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8587 - accuracy: 0.6629 - val_loss: 0.8275 - val_accuracy: 0.6671\n",
      "Epoch 4/20\n",
      "72516/72516 [==============================] - 192s 3ms/step - loss: 0.8566 - accuracy: 0.6636 - val_loss: 0.8242 - val_accuracy: 0.6733\n",
      "Epoch 5/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8556 - accuracy: 0.6640 - val_loss: 0.8275 - val_accuracy: 0.6721\n",
      "Epoch 6/20\n",
      "72516/72516 [==============================] - 191s 3ms/step - loss: 0.8551 - accuracy: 0.6643 - val_loss: 0.8255 - val_accuracy: 0.6691\n",
      "Epoch 7/20\n",
      "72516/72516 [==============================] - 191s 3ms/step - loss: 0.8547 - accuracy: 0.6646 - val_loss: 0.8214 - val_accuracy: 0.6759\n",
      "Epoch 8/20\n",
      "72516/72516 [==============================] - 189s 3ms/step - loss: 0.8545 - accuracy: 0.6647 - val_loss: 0.8216 - val_accuracy: 0.6737\n",
      "Epoch 9/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8538 - accuracy: 0.6652 - val_loss: 0.8273 - val_accuracy: 0.6657\n",
      "Epoch 10/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8533 - accuracy: 0.6650 - val_loss: 0.8198 - val_accuracy: 0.6749\n",
      "Epoch 11/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8536 - accuracy: 0.6649 - val_loss: 0.8218 - val_accuracy: 0.6730\n",
      "Epoch 12/20\n",
      "72516/72516 [==============================] - 189s 3ms/step - loss: 0.8530 - accuracy: 0.6653 - val_loss: 0.8223 - val_accuracy: 0.6746\n",
      "Epoch 13/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8534 - accuracy: 0.6650 - val_loss: 0.8238 - val_accuracy: 0.6730\n",
      "Epoch 14/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8533 - accuracy: 0.6655 - val_loss: 0.8204 - val_accuracy: 0.6750\n",
      "Epoch 15/20\n",
      "72516/72516 [==============================] - 189s 3ms/step - loss: 0.8527 - accuracy: 0.6653 - val_loss: 0.8194 - val_accuracy: 0.6722\n",
      "Epoch 16/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8532 - accuracy: 0.6652 - val_loss: 0.8259 - val_accuracy: 0.6711\n",
      "Epoch 17/20\n",
      "72516/72516 [==============================] - 189s 3ms/step - loss: 0.8528 - accuracy: 0.6656 - val_loss: 0.8237 - val_accuracy: 0.6683\n",
      "Epoch 18/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8526 - accuracy: 0.6657 - val_loss: 0.8234 - val_accuracy: 0.6687\n",
      "Epoch 19/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8527 - accuracy: 0.6655 - val_loss: 0.8251 - val_accuracy: 0.6670\n",
      "Epoch 20/20\n",
      "72516/72516 [==============================] - 190s 3ms/step - loss: 0.8522 - accuracy: 0.6657 - val_loss: 0.8350 - val_accuracy: 0.6615\n",
      "15540/15540 [==============================] - 12s 796us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m y_test_pred_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(y_test_pred, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Print the classification report\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mprint\u001b[39m(classification_report(y_test, y_test_pred_classes))\n\u001b[1;32m     32\u001b[0m \u001b[39m# Print the test accuracy\u001b[39;00m\n\u001b[1;32m     33\u001b[0m test_accuracy \u001b[39m=\u001b[39m accuracy_score(y_test, y_test_pred_classes)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2313\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2310\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   2312\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2313\u001b[0m     labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n\u001b[1;32m   2314\u001b[0m     labels_given \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2315\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/multiclass.py:117\u001b[0m, in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(\u001b[39misinstance\u001b[39m(label, \u001b[39mstr\u001b[39m) \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m ys_labels)) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMix of label input types (string and number)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(\u001b[39msorted\u001b[39m(ys_labels))\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dropout(0.4))  # Dropout layer after the input layer\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "model.add(Dropout(0.4))  # Dropout layer after the hidden layer\n",
    "model.add(Dense(5, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_val, y_val_encoded), epochs=20, batch_size=32)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert these probabilities to class labels\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_test_pred_classes))\n",
    "\n",
    "# Print the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15540/15540 [==============================] - 13s 804us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.00      0.00      0.00     12678\n",
      "         pop       0.58      0.95      0.72    215348\n",
      "         rap       0.87      0.83      0.85    149475\n",
      "          rb       0.56      0.00      0.00     23801\n",
      "        rock       0.69      0.01      0.03     95947\n",
      "\n",
      "    accuracy                           0.66    497249\n",
      "   macro avg       0.54      0.36      0.32    497249\n",
      "weighted avg       0.67      0.66      0.57    497249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_encoded = to_categorical(encoder.transform(y_test))\n",
    "\n",
    "# The model's predictions are probabilities for each class. To use them in the classification report,\n",
    "# we need to convert these probabilities to class labels. We can do this by taking the class with the highest probability.\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Similarly, convert y_test_encoded back to labels\n",
    "y_test_labels = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_labels, y_test_pred_classes, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "72516/72516 [==============================] - 177s 2ms/step - loss: 0.8181 - accuracy: 0.6747 - val_loss: 0.8042 - val_accuracy: 0.6791\n",
      "Epoch 2/20\n",
      "72516/72516 [==============================] - 174s 2ms/step - loss: 0.8018 - accuracy: 0.6795 - val_loss: 0.7970 - val_accuracy: 0.6816\n",
      "Epoch 3/20\n",
      "72516/72516 [==============================] - 173s 2ms/step - loss: 0.7978 - accuracy: 0.6809 - val_loss: 0.7952 - val_accuracy: 0.6812\n",
      "Epoch 4/20\n",
      "72516/72516 [==============================] - 176s 2ms/step - loss: 0.7957 - accuracy: 0.6817 - val_loss: 0.7938 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "72516/72516 [==============================] - 173s 2ms/step - loss: 0.7942 - accuracy: 0.6819 - val_loss: 0.7920 - val_accuracy: 0.6823\n",
      "Epoch 6/20\n",
      "72516/72516 [==============================] - 174s 2ms/step - loss: 0.7930 - accuracy: 0.6826 - val_loss: 0.7920 - val_accuracy: 0.6831\n",
      "Epoch 7/20\n",
      "72516/72516 [==============================] - 173s 2ms/step - loss: 0.7924 - accuracy: 0.6826 - val_loss: 0.7914 - val_accuracy: 0.6828\n",
      "Epoch 8/20\n",
      "72516/72516 [==============================] - 173s 2ms/step - loss: 0.7919 - accuracy: 0.6829 - val_loss: 0.7954 - val_accuracy: 0.6803\n",
      "Epoch 9/20\n",
      "72516/72516 [==============================] - 174s 2ms/step - loss: 0.7915 - accuracy: 0.6829 - val_loss: 0.7935 - val_accuracy: 0.6807\n",
      "Epoch 10/20\n",
      "72516/72516 [==============================] - 175s 2ms/step - loss: 0.7912 - accuracy: 0.6831 - val_loss: 0.7889 - val_accuracy: 0.6838\n",
      "Epoch 11/20\n",
      "72516/72516 [==============================] - 174s 2ms/step - loss: 0.7909 - accuracy: 0.6831 - val_loss: 0.7914 - val_accuracy: 0.6832\n",
      "Epoch 12/20\n",
      "51504/72516 [====================>.........] - ETA: 46s - loss: 0.7902 - accuracy: 0.6832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     15\u001b[0m               optimizer\u001b[39m=\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m, beta_1\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, beta_2\u001b[39m=\u001b[39m\u001b[39m0.999\u001b[39m, epsilon\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m), \n\u001b[1;32m     16\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train_encoded, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val_encoded), epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m \u001b[39m# Generate predictions for the test set\u001b[39;00m\n\u001b[1;32m     22\u001b[0m y_test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:142\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m--> 142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:342\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_define_function\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs):\n\u001b[1;32m    322\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[1;32m    324\u001b[0m \u001b[39m  Caller must hold self._lock.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39m      shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m    341\u001b[0m   args, kwargs, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 342\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_spec\u001b[39m.\u001b[39;49mcanonicalize_function_inputs(args, kwargs))\n\u001b[1;32m    344\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    345\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature, \u001b[39m*\u001b[39margs[\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature):])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:407\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_pure:\n\u001b[1;32m    406\u001b[0m   args, kwargs \u001b[39m=\u001b[39m _convert_variables_to_tensors(args, kwargs)\n\u001b[0;32m--> 407\u001b[0m args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_function_inputs(args, kwargs)\n\u001b[1;32m    408\u001b[0m args, kwargs \u001b[39m=\u001b[39m cast_inputs(args, kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature)\n\u001b[1;32m    409\u001b[0m filtered_flat_args \u001b[39m=\u001b[39m filter_function_inputs(args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:425\u001b[0m, in \u001b[0;36mFunctionSpec.bind_function_inputs\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mName collision after sanitization. Please rename \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtf.function input parameters. Original: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msorted\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m, Sanitized: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39msorted\u001b[39m(sanitized_kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 425\u001b[0m   bound_arguments \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mbind_with_defaults(\n\u001b[1;32m    426\u001b[0m       args, sanitized_kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_values)\n\u001b[1;32m    427\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    428\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    429\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBinding inputs to tf.function `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name\u001b[39m}\u001b[39;00m\u001b[39m` failed due to `\u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    430\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived args: \u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m}\u001b[39;00m\u001b[39m and kwargs: \u001b[39m\u001b[39m{\u001b[39;00msanitized_kwargs\u001b[39m}\u001b[39;00m\u001b[39m for signature:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    431\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m   ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:224\u001b[0m, in \u001b[0;36mFunctionType.bind_with_defaults\u001b[0;34m(self, args, kwargs, default_values)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns BoundArguments with default values filled in.\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m bound_arguments \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 224\u001b[0m bound_arguments\u001b[39m.\u001b[39;49mapply_defaults()\n\u001b[1;32m    226\u001b[0m with_default_args \u001b[39m=\u001b[39m collections\u001b[39m.\u001b[39mOrderedDict()\n\u001b[1;32m    227\u001b[0m \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m bound_arguments\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/lib/python3.10/inspect.py:2846\u001b[0m, in \u001b[0;36mBoundArguments.apply_defaults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2844\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signature\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2845\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2846\u001b[0m         new_arguments\u001b[39m.\u001b[39mappend((name, arguments[name]))\n\u001b[1;32m   2847\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m   2848\u001b[0m         \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mdefault \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m _empty:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  # Input layer\n",
    "model.add(Dense(64, activation='relu'))  # Hidden layer\n",
    "model.add(Dense(5, activation='sigmoid'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_val, y_val_encoded), epochs=20, batch_size=32)\n",
    "\n",
    "# Generate predictions for the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Convert these probabilities to class labels\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# Print the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend LokyBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          505     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.73469D+06    |proj g|=  1.33281D+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.02530D+06    |proj g|=  6.20453D+03\n",
      "\n",
      "At iterate  100    f=  2.01568D+06    |proj g|=  6.84884D+03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  505    100    115      1     0     0   6.849D+03   2.016D+06\n",
      "  F =   2015675.7591657985     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=31)]: Done   1 out of   1 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.28      0.03      0.05     12678\n",
      "         pop       0.59      0.86      0.70    215348\n",
      "         rap       0.82      0.83      0.82    149475\n",
      "          rb       0.29      0.03      0.05     23801\n",
      "        rock       0.56      0.18      0.28     95947\n",
      "\n",
      "    accuracy                           0.66    497249\n",
      "   macro avg       0.51      0.39      0.38    497249\n",
      "weighted avg       0.63      0.66      0.61    497249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "log_reg = LogisticRegression(n_jobs=31, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=31)]: Using backend LokyBackend with 31 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          505     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.08706D+06    |proj g|=  6.01676D+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  5.59375D+06    |proj g|=  2.65158D+04\n",
      "\n",
      "At iterate  100    f=  5.56343D+06    |proj g|=  9.06419D+03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  505    100    107      1     0     0   9.064D+03   5.563D+06\n",
      "  F =   5563431.1261054790     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=31)]: Done   1 out of   1 | elapsed:  5.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.11      0.67      0.19     12678\n",
      "         pop       0.68      0.23      0.34    215348\n",
      "         rap       0.85      0.78      0.82    149475\n",
      "          rb       0.16      0.57      0.25     23801\n",
      "        rock       0.42      0.55      0.48     95947\n",
      "\n",
      "    accuracy                           0.49    497249\n",
      "   macro avg       0.44      0.56      0.42    497249\n",
      "weighted avg       0.64      0.49      0.50    497249\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = np.vstack(df['word2vec_lyrics'].values)\n",
    "y = df['tag']\n",
    "\n",
    "# Split the data into 70% train and 30% temporary test set\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Initialize the Random Over Sampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and resample the training data\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "log_reg = LogisticRegression(n_jobs=31, verbose=1)\n",
    "\n",
    "# Fit the model\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.11      0.67      0.19     12678\n",
      "         pop       0.68      0.23      0.34    215348\n",
      "         rap       0.85      0.78      0.82    149475\n",
      "          rb       0.16      0.57      0.25     23801\n",
      "        rock       0.42      0.55      0.48     95947\n",
      "\n",
      "    accuracy                           0.49    497249\n",
      "   macro avg       0.44      0.56      0.42    497249\n",
      "weighted avg       0.64      0.49      0.50    497249\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
