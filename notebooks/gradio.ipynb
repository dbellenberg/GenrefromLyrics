{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.21MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 44.8kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 570/570 [00:00<00:00, 944kB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'number_of_genres' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Load BERT model and tokenizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m BertForSequenceClassification\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39m/work/NLP_Project/GenreFromLyricsShared/\u001b[39m\u001b[39m'\u001b[39m, num_labels\u001b[39m=\u001b[39mnumber_of_genres)  \u001b[39m# specify the number of genres\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(lyrics):\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mencode_plus(lyrics, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'number_of_genres' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "import joblib\n",
    "import re\n",
    "import gradio as gr\n",
    "\n",
    "# Load your trained Word2Vec model\n",
    "w2v_model = Word2Vec.load('/work/NLP_Project/GenreFromLyricsShared/Word2VecModels/original_w2v.model')\n",
    "\n",
    "def preprocess(lyrics):\n",
    "    #stop = stopwords.words('english')\n",
    "    lyrics = re.sub('\\n', ' ', lyrics)\n",
    "    lyrics = re.sub('\\[.*?\\]', '', lyrics)\n",
    "    lyrics = re.sub('\\\\[^\\s]*', '', lyrics)\n",
    "    lyrics = re.sub(\"'\", '', lyrics)\n",
    "    lyrics = lyrics.strip()\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics)\n",
    "    lyrics = re.sub('['+string.punctuation+']', '', lyrics)\n",
    "    lyrics = lyrics.lower()\n",
    "    lyrics = re.sub('chorus', '', lyrics)\n",
    "    lyrics = re.sub('verse', '', lyrics)\n",
    "    #lyrics = ' '.join([word for word in lyrics.split() if word not in stop])\n",
    "    tokens = nltk.word_tokenize(lyrics)\n",
    "\n",
    "    # Use Word2Vec model to generate word vectors and then calculate the mean vector\n",
    "    vector = np.mean([w2v_model.wv[word] for word in tokens if word in w2v_model.wv.key_to_index], axis=0)\n",
    "    return vector\n",
    "\n",
    "def predict_genre(Artist, Title, Lyrics, File):\n",
    "    # Preprocess the lyrics\n",
    "    vector = preprocess(lyrics)\n",
    "\n",
    "    # Reshape the vector to 2D array as the model.predict expects 2D array\n",
    "    vector = vector.reshape(1, -1)\n",
    "\n",
    "    # Load the trained Random Forest Classifier\n",
    "    clf = joblib.load('/work/NLP_Project/GenreFromLyricsShared/random_forest.sav')\n",
    "\n",
    "    # Get the probabilities of each class\n",
    "    probabilities = clf.predict_proba(vector)[0]\n",
    "\n",
    "    # Map each probability with the corresponding genre\n",
    "    genres = clf.classes_\n",
    "    result = {genre: prob for genre, prob in zip(genres, probabilities)}\n",
    "\n",
    "    return result\n",
    "\n",
    "description = '<img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\">'\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_genre,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Artist Here...'),\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Title Here...'),\n",
    "        gr.inputs.Textbox(lines=4, placeholder='Lyrics Here...'),\n",
    "        #gr.inputs.File()\n",
    "    ],\n",
    "    outputs=gr.outputs.Label(label=\"Genre Suggestion\"),\n",
    "    description=description\n",
    ")\n",
    "iface.launch(debug=True, share=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at '/work/NLP_Project/GenreFromLyricsShared/epoch=1-step=145040.ckpt' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:659\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    658\u001b[0m     \u001b[39m# Load config dict\u001b[39;00m\n\u001b[0;32m--> 659\u001b[0m     config_dict \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_dict_from_json_file(resolved_config_file)\n\u001b[1;32m    660\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:750\u001b[0m, in \u001b[0;36mPretrainedConfig._dict_from_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(json_file, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m reader:\n\u001b[0;32m--> 750\u001b[0m     text \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    751\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39mloads(text)\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    321\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer_decode(data, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors, final)\n\u001b[1;32m    323\u001b[0m \u001b[39m# keep undecoded input until the next call\u001b[39;00m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Load BERT model and tokenizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m model \u001b[39m=\u001b[39m BertForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m'\u001b[39;49m\u001b[39m/work/NLP_Project/GenreFromLyricsShared/epoch=1-step=145040.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m, num_labels\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)  \u001b[39m# specify the number of genres\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(lyrics):\n\u001b[1;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mencode_plus(lyrics, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2251\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2250\u001b[0m     config_path \u001b[39m=\u001b[39m config \u001b[39mif\u001b[39;00m config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m pretrained_model_name_or_path\n\u001b[0;32m-> 2251\u001b[0m     config, model_kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m   2252\u001b[0m         config_path,\n\u001b[1;32m   2253\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2254\u001b[0m         return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2255\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m   2256\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m   2257\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   2258\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   2259\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m   2260\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2261\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m   2262\u001b[0m         _from_auto\u001b[39m=\u001b[39;49mfrom_auto_class,\n\u001b[1;32m   2263\u001b[0m         _from_pipeline\u001b[39m=\u001b[39;49mfrom_pipeline,\n\u001b[1;32m   2264\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2265\u001b[0m     )\n\u001b[1;32m   2266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2267\u001b[0m     model_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:547\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    470\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPretrainedConfig\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    471\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[39m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 547\u001b[0m     config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    548\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type:\n\u001b[1;32m    549\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    550\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are using a model of type \u001b[39m\u001b[39m{\u001b[39;00mconfig_dict[\u001b[39m'\u001b[39m\u001b[39mmodel_type\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m to instantiate a model of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mmodel_type\u001b[39m}\u001b[39;00m\u001b[39m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    552\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:574\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    573\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n\u001b[1;32m    576\u001b[0m     original_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:662\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    660\u001b[0m     config_dict[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m commit_hash\n\u001b[1;32m    661\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m):\n\u001b[0;32m--> 662\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    663\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIt looks like the config file at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is not a valid JSON file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    664\u001b[0m     )\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m is_local:\n\u001b[1;32m    667\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading configuration file \u001b[39m\u001b[39m{\u001b[39;00mresolved_config_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: It looks like the config file at '/work/NLP_Project/GenreFromLyricsShared/epoch=1-step=145040.ckpt' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import gradio as gr\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('/work/NLP_Project/GenreFromLyricsShared/epoch=1-step=145040.ckpt', num_labels=5)  # specify the number of genres\n",
    "\n",
    "def preprocess(lyrics):\n",
    "    return tokenizer.encode_plus(lyrics, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "def predict_genre(Artist, Title, Lyrics, File):\n",
    "    # Preprocess the lyrics\n",
    "    inputs = preprocess(Lyrics)\n",
    "\n",
    "    # Get the probabilities of each class\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "    # Map each probability with the corresponding genre\n",
    "    genres = clf.classes_\n",
    "    result = {genre: prob for genre, prob in zip(genres, probabilities.tolist()[0])}\n",
    "\n",
    "    return result\n",
    "\n",
    "description = '<img src=\"https://storage.googleapis.com/pr-newsroom-wp/1/2018/11/Spotify_Logo_CMYK_Green.png\" alt=\"Spotify Logo\">'\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_genre,\n",
    "    inputs=[\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Artist Here...'),\n",
    "        gr.inputs.Textbox(lines=1, placeholder='Title Here...'),\n",
    "        gr.inputs.Textbox(lines=4, placeholder='Lyrics Here...'),\n",
    "        #gr.inputs.File()\n",
    "    ],\n",
    "    outputs=gr.outputs.Label(label=\"Genre Suggestion\"),\n",
    "    description=description\n",
    ")\n",
    "iface.launch(debug=True, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
