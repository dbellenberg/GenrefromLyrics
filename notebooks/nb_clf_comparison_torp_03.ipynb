{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas==2.0.1 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: numpy==1.24.3 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.24.3)\n",
      "Requirement already satisfied: matplotlib==3.7.1 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: tqdm==4.65.0 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.65.0)\n",
      "Requirement already satisfied: fasttext==0.9.2 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.9.2)\n",
      "Requirement already satisfied: seaborn==0.12.2 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.12.2)\n",
      "Requirement already satisfied: nltk==3.8.1 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /home/ucloud/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas==2.0.1->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas==2.0.1->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/ucloud/.local/lib/python3.10/site-packages (from pandas==2.0.1->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ucloud/.local/lib/python3.10/site-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.7.1->-r requirements.txt (line 3)) (3.0.7)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/ucloud/.local/lib/python3.10/site-packages (from fasttext==0.9.2->-r requirements.txt (line 5)) (2.10.4)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/lib/python3/dist-packages (from fasttext==0.9.2->-r requirements.txt (line 5)) (59.6.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/ucloud/.local/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ucloud/.local/lib/python3.10/site-packages (from nltk==3.8.1->-r requirements.txt (line 7)) (2023.5.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ucloud/.local/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 8)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ucloud/.local/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.1->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: imbalanced-learn in /home/ucloud/.local/lib/python3.10/site-packages (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ucloud/.local/lib/python3.10/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ucloud/.local/lib/python3.10/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ucloud/.local/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ucloud/.local/lib/python3.10/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ucloud/.local/lib/python3.10/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import fasttext\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import NaiveBayesClassifier\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classification(train, label, vectorizer='bow', n_top_features=10, oversample=False):\n",
    "\n",
    "    train = train.apply(' '.join)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, label, test_size=0.3, random_state=42)\n",
    "\n",
    "    if vectorizer == 'bow':\n",
    "        vec = CountVectorizer()\n",
    "    elif vectorizer == 'tfidf':\n",
    "        vec = TfidfVectorizer()\n",
    "\n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "\n",
    "    # Initialize the MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # Perform random oversampling if enabled\n",
    "    if oversample:\n",
    "        oversampler = RandomOverSampler(random_state=42)\n",
    "        X_train_vec, y_train = oversampler.fit_resample(X_train_vec, y_train)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    nb.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Print the most informative features\n",
    "    feature_names = vec.get_feature_names_out()\n",
    "    for i, class_label in enumerate(nb.classes_):\n",
    "        print(f\"\\nClass: {class_label}\")\n",
    "        top_features_idx = nb.feature_log_prob_[i].argsort()[-n_top_features:][::-1]\n",
    "        top_features = [feature_names[idx] for idx in top_features_idx]\n",
    "        print(\", \".join(top_features))\n",
    "\n",
    "    # Predict the labels of the test set\n",
    "    y_pred = nb.predict(X_test_vec)\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_classification(train, label, vectorizer_method='tfidf', oversample=False, n_top_features=10):\n",
    "\n",
    "    train = train.apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # split into train and test sets, with stratifying\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(train, label, test_size=0.3, random_state=42, stratify=label)\n",
    "\n",
    "    # Split the temporary test set into 50% test and 50% validation (15% of the total data each)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # Initialize vectorizer (TDIDF OR bag of words)\n",
    "    if vectorizer_method == 'tdidf':\n",
    "        vectorizer = TfidfVectorizer()\n",
    "    elif vectorizer_method == 'bow':\n",
    "        vectorizer = CountVectorizer()\n",
    "    \n",
    "    # Vectorize data\n",
    "    X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "    X_val_vectors = vectorizer.transform(X_val)\n",
    "    X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "    # Perform oversampling\n",
    "    if oversample == True:\n",
    "        oversampler = RandomOverSampler(random_state=42)\n",
    "        X_train_vectors, y_train = oversampler.fit_resample(X_train_vectors, y_train)\n",
    "\n",
    "    # Initialize the Multinomial LR\n",
    "    lr_clf = LogisticRegression(multi_class='multinomial', solver='lbfgs', n_jobs=-1)\n",
    "\n",
    "    # Fit the model to the training data \n",
    "    lr_clf.fit(X_train_vectors, y_train)\n",
    "  \n",
    "    # Get the feature names from the vectorizer\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "  \n",
    "    # Print the most informative features\n",
    "    for i, label in enumerate(lr_clf.classes_):\n",
    "        print(f\"\\nClass: {label}\")\n",
    "        top_features_idx = lr_clf.coef_[i].argsort()[-n_top_features:][::-1]\n",
    "        top_features = [feature_names[idx] for idx in top_features_idx]\n",
    "        print(\", \".join(top_features))\n",
    "\n",
    "    # Predict the labels of the test set\n",
    "    y_test_pred = lr_clf.predict(X_test_vectors)\n",
    "    y_val_pred = lr_clf.predict(X_val_vectors)\n",
    "\n",
    "    # Generate classification report\n",
    "    test_report = classification_report(y_test, y_test_pred)\n",
    "    val_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "    return test_report, val_report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./pkl_files/tokenized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invite, somethin,...</td>\n",
       "      <td>3</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>[maybe, cause, im, eatin, bastards, fiend, gru...</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[ugh, killa, baby, kanye, 1970s, heron, flow, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   \n",
       "0          Killa Cam  rap    Cam'ron  2004  \\\n",
       "1         Can I Live  rap      JAY-Z  1996   \n",
       "2  Forgive Me Father  rap   Fabolous  2003   \n",
       "3       Down and Out  rap    Cam'ron  2004   \n",
       "4             Fly In  rap  Lil Wayne  2005   \n",
       "\n",
       "                                              lyrics  id  lyrics_word_count  \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...   1                762  \n",
       "1  [yeah, hah, yeah, rocafella, invite, somethin,...   3                548  \n",
       "2  [maybe, cause, im, eatin, bastards, fiend, gru...   4                574  \n",
       "3  [ugh, killa, baby, kanye, 1970s, heron, flow, ...   5                760  \n",
       "4  [ask, young, boy, gon, second, time, around, g...   6                432  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "im, love, like, dont, know, got, na, oh, one, time\n",
      "\n",
      "Class: pop\n",
      "im, love, know, dont, like, oh, na, got, go, time\n",
      "\n",
      "Class: rap\n",
      "im, like, got, know, get, yeah, dont, shit, aint, na\n",
      "\n",
      "Class: rb\n",
      "love, im, know, yeah, dont, like, got, baby, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, time, love, na, never, oh, got\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.33      0.18      0.23     25477\n",
      "         pop       0.65      0.49      0.56    430965\n",
      "         rap       0.83      0.79      0.81    298959\n",
      "          rb       0.24      0.35      0.29     47343\n",
      "        rock       0.40      0.62      0.48    191812\n",
      "\n",
      "    accuracy                           0.59    994556\n",
      "   macro avg       0.49      0.49      0.48    994556\n",
      "weighted avg       0.63      0.59      0.60    994556\n",
      "\n",
      "CPU times: user 5min 58s, sys: 19.5 s, total: 6min 17s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & Bag of Words\n",
    "bow_nb_report = nb_classification(df['lyrics'], df['tag'], vectorizer='bow')\n",
    "print(bow_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "love, im, dont, know, like, oh, got, na, one, youre\n",
      "\n",
      "Class: pop\n",
      "love, im, dont, know, oh, na, like, youre, time, go\n",
      "\n",
      "Class: rap\n",
      "im, like, got, yeah, get, dont, shit, bitch, know, nigga\n",
      "\n",
      "Class: rb\n",
      "love, baby, yeah, know, im, oh, dont, na, got, like\n",
      "\n",
      "Class: rock\n",
      "im, dont, know, time, love, youre, never, oh, like, see\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.00      0.00      0.00     25477\n",
      "         pop       0.58      0.91      0.71    430965\n",
      "         rap       0.80      0.83      0.82    298959\n",
      "          rb       0.13      0.00      0.00     47343\n",
      "        rock       0.69      0.05      0.09    191812\n",
      "\n",
      "    accuracy                           0.65    994556\n",
      "   macro avg       0.44      0.36      0.32    994556\n",
      "weighted avg       0.63      0.65      0.57    994556\n",
      "\n",
      "CPU times: user 6min 3s, sys: 20.6 s, total: 6min 24s\n",
      "Wall time: 6min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & TFIDF\n",
    "tfidf_nb_report = nb_classification(df['lyrics'], df['tag'], vectorizer='tfidf')\n",
    "print(tfidf_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5023785, 2303387)\n",
      "\n",
      "Class: country\n",
      "im, love, like, dont, know, got, na, oh, one, time\n",
      "\n",
      "Class: pop\n",
      "im, love, know, dont, like, oh, na, got, go, time\n",
      "\n",
      "Class: rap\n",
      "im, like, got, know, get, yeah, dont, shit, aint, na\n",
      "\n",
      "Class: rb\n",
      "love, know, im, yeah, dont, got, like, baby, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, time, love, na, never, oh, got\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.14      0.67      0.23     25477\n",
      "         pop       0.70      0.18      0.29    430965\n",
      "         rap       0.86      0.75      0.80    298959\n",
      "          rb       0.17      0.59      0.26     47343\n",
      "        rock       0.38      0.65      0.48    191812\n",
      "\n",
      "    accuracy                           0.48    994556\n",
      "   macro avg       0.45      0.57      0.41    994556\n",
      "weighted avg       0.65      0.48      0.48    994556\n",
      "\n",
      "CPU times: user 6min 18s, sys: 24.7 s, total: 6min 43s\n",
      "Wall time: 6min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Naive Bayes & Bag of Words\n",
    "ros_bow_nb_report = nb_classification(df['lyrics'], df['tag'], vectorizer='bow', oversample=True)\n",
    "print(ros_bow_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect RAM from garbage to prevent kernel from dying\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "lonesome, truck, porch, whiskey, tennessee, guitar, texas, memory, cowboy, folks, tailgate, hed, heartaches, heartache, bar, instrumental, headed, darlin, creek, boots\n",
      "\n",
      "Class: pop\n",
      "rap, fk, fcking, fck, chuckle, pre, niggas, spoken, fking, endless, nigga, evry, sung, mcs, cos, disease, fkin, refrain, mic, noone\n",
      "\n",
      "Class: rap\n",
      "rapping, snippet, lyrics, rapper, rappers, rap, intro, raps, fam, rhymes, bars, spitting, hook, depression, opps, pen, bro, niggas, bruh, booth\n",
      "\n",
      "Class: rb\n",
      "pre, tryna, outro, trynna, niggas, 2x, hook, imma, nigga, shawty, intro, focused, bitches, crib, hella, finna, henny, vibe, x2, stress\n",
      "\n",
      "Class: rock\n",
      "thе, endless, fz, disease, punk, guitar, teeth, failure, decay, tongues, filth, collapse, drag, fucking, despair, apathy, destroy, desperate, crawling, noose\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.47      0.12      0.19     12677\n",
      "         pop       0.61      0.86      0.71    215359\n",
      "         rap       0.87      0.82      0.85    149486\n",
      "          rb       0.40      0.10      0.16     23802\n",
      "        rock       0.57      0.25      0.35     95954\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.58      0.43      0.45    497278\n",
      "weighted avg       0.67      0.68      0.64    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.46      0.12      0.19     12678\n",
      "         pop       0.61      0.86      0.71    215358\n",
      "         rap       0.87      0.82      0.85    149487\n",
      "          rb       0.40      0.10      0.16     23802\n",
      "        rock       0.57      0.25      0.35     95953\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.58      0.43      0.45    497278\n",
      "weighted avg       0.67      0.68      0.64    497278\n",
      "\n",
      "CPU times: user 6min 12s, sys: 45.6 s, total: 6min 58s\n",
      "Wall time: 16min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & Bag of Words\n",
    "bow_lr_test_report, bow_lr_val_report = lr_classification(df['lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='bow',\n",
    "                                                    n_top_features=20)\n",
    "print(bow_lr_test_report, bow_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "country, whiskey, old, beer, truck, town, id, well, lonesome, cowboy, bar, memory, tennessee, little, ol, texas, wind, kiss, aint, arms\n",
      "\n",
      "Class: pop\n",
      "repeat, pre, fcking, cos, fck, spoken, dey, yo, fk, well, fking, flesh, club, endless, noone, sea, burning, rules, suddenly, niggas\n",
      "\n",
      "Class: rap\n",
      "rap, hook, li, bro, rhymes, gang, rappers, bitch, tryna, bars, rapper, lil, homie, rapping, mic, lyrics, ayy, dude, yo, flow\n",
      "\n",
      "Class: rb\n",
      "tryna, hook, ima, nigga, imma, pre, vibe, bout, shit, x2, shawty, ain, niggas, yea, feelings, mmm, bae, babe, baby, yo\n",
      "\n",
      "Class: rock\n",
      "thе, fucking, well, band, sick, death, teeth, dead, void, guitar, punk, blood, drag, goddamn, endless, disease, everyone, machine, anyway, mouth\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.52      0.11      0.18     12677\n",
      "         pop       0.62      0.85      0.72    215359\n",
      "         rap       0.86      0.85      0.85    149486\n",
      "          rb       0.47      0.08      0.14     23802\n",
      "        rock       0.57      0.29      0.38     95954\n",
      "\n",
      "    accuracy                           0.69    497278\n",
      "   macro avg       0.61      0.44      0.46    497278\n",
      "weighted avg       0.67      0.69      0.65    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.51      0.11      0.18     12678\n",
      "         pop       0.62      0.85      0.72    215358\n",
      "         rap       0.86      0.85      0.85    149487\n",
      "          rb       0.46      0.08      0.14     23802\n",
      "        rock       0.56      0.29      0.38     95953\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.60      0.44      0.45    497278\n",
      "weighted avg       0.67      0.68      0.65    497278\n",
      "\n",
      "CPU times: user 6min 31s, sys: 50.4 s, total: 7min 22s\n",
      "Wall time: 16min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & TDIDF\n",
    "tfidf_lr_test_report, tfidf_lr_val_report = lr_classification(df['lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    n_top_features=20)\n",
    "print(tfidf_lr_test_report, tfidf_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "truck, whiskey, country, beer, cowboy, bar, ol, tennessee, old, boots, porch, heartaches, texas, instrumental, lonesome, tailgate, county, guitar, honky, town\n",
      "\n",
      "Class: pop\n",
      "cos, repeat, spoken, yo, pre, bitch, fcking, endless, club, noone, flesh, fck, dey, nae, machine, sea, youve, tv, colour, ga\n",
      "\n",
      "Class: rap\n",
      "rap, tryna, hook, nigga, niggas, rappers, rhymes, li, shit, yo, mic, bro, imma, flow, homie, rapper, bars, lyrics, rapping, lil\n",
      "\n",
      "Class: rb\n",
      "tryna, hook, pre, niggas, imma, nigga, ima, vibe, yo, shit, outro, shawty, funky, bae, energy, yall, x2, bout, type, funk\n",
      "\n",
      "Class: rock\n",
      "disease, fucking, band, void, teeth, punk, well, drag, destroy, sick, machine, decay, scream, crawling, metal, endless, thе, goddamn, guitar, lungs\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.15      0.69      0.24     12677\n",
      "         pop       0.69      0.32      0.44    215359\n",
      "         rap       0.89      0.79      0.83    149486\n",
      "          rb       0.19      0.59      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95954\n",
      "\n",
      "    accuracy                           0.54    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.67      0.54      0.56    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.15      0.70      0.25     12678\n",
      "         pop       0.69      0.32      0.44    215358\n",
      "         rap       0.89      0.79      0.83    149487\n",
      "          rb       0.19      0.59      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95953\n",
      "\n",
      "    accuracy                           0.54    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.67      0.54      0.56    497278\n",
      "\n",
      "CPU times: user 6min 37s, sys: 1min 1s, total: 7min 39s\n",
      "Wall time: 22min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Logistic regression & TDIDF\n",
    "ros_tfidf_lr_test_report, ros_tfidf_lr_val_report = lr_classification(df['lyrics'], df['tag'],\n",
    "                                                    oversample=True,\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    n_top_features=20)\n",
    "print(ros_tfidf_lr_test_report, ros_tfidf_lr_val_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./pkl_files/stemmed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics_word_count</th>\n",
       "      <th>stemmed_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invite, somethin,...</td>\n",
       "      <td>3</td>\n",
       "      <td>548</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invit, somethin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>[maybe, cause, im, eatin, bastards, fiend, gru...</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>[mayb, caus, im, eatin, bastard, fiend, grub, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[ugh, killa, baby, kanye, 1970s, heron, flow, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>760</td>\n",
       "      <td>[ugh, killa, babi, kany, 1970s, heron, flow, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   \n",
       "0          Killa Cam  rap    Cam'ron  2004  \\\n",
       "1         Can I Live  rap      JAY-Z  1996   \n",
       "2  Forgive Me Father  rap   Fabolous  2003   \n",
       "3       Down and Out  rap    Cam'ron  2004   \n",
       "4             Fly In  rap  Lil Wayne  2005   \n",
       "\n",
       "                                              lyrics  id  lyrics_word_count   \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...   1                762  \\\n",
       "1  [yeah, hah, yeah, rocafella, invite, somethin,...   3                548   \n",
       "2  [maybe, cause, im, eatin, bastards, fiend, gru...   4                574   \n",
       "3  [ugh, killa, baby, kanye, 1970s, heron, flow, ...   5                760   \n",
       "4  [ask, young, boy, gon, second, time, around, g...   6                432   \n",
       "\n",
       "                                      stemmed_lyrics  \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...  \n",
       "1  [yeah, hah, yeah, rocafella, invit, somethin, ...  \n",
       "2  [mayb, caus, im, eatin, bastard, fiend, grub, ...  \n",
       "3  [ugh, killa, babi, kany, 1970s, heron, flow, h...  \n",
       "4  [ask, young, boy, gon, second, time, around, g...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "im, love, like, know, dont, got, na, go, get, time\n",
      "\n",
      "Class: pop\n",
      "im, love, know, dont, like, oh, na, go, got, get\n",
      "\n",
      "Class: rap\n",
      "im, like, got, get, know, nigga, yeah, dont, fuck, bitch\n",
      "\n",
      "Class: rb\n",
      "love, know, im, yeah, dont, like, got, babi, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, love, time, go, one, come, feel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.32      0.18      0.23     25477\n",
      "         pop       0.65      0.48      0.55    430965\n",
      "         rap       0.83      0.79      0.81    298959\n",
      "          rb       0.24      0.35      0.28     47343\n",
      "        rock       0.39      0.63      0.48    191812\n",
      "\n",
      "    accuracy                           0.59    994556\n",
      "   macro avg       0.48      0.49      0.47    994556\n",
      "weighted avg       0.63      0.59      0.59    994556\n",
      "\n",
      "CPU times: user 5min 28s, sys: 16.2 s, total: 5min 44s\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & Bag of Words\n",
    "bow_nb_report = nb_classification(df['stemmed_lyrics'], df['tag'], vectorizer='bow')\n",
    "print(bow_nb_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "love, im, know, dont, like, oh, time, got, go, one\n",
      "\n",
      "Class: pop\n",
      "love, im, know, dont, oh, like, na, go, your, time\n",
      "\n",
      "Class: rap\n",
      "im, nigga, like, got, fuck, bitch, yeah, get, shit, dont\n",
      "\n",
      "Class: rb\n",
      "love, babi, yeah, know, im, dont, oh, na, got, like\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, time, love, feel, your, never, go, one\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.00      0.00      0.00     25477\n",
      "         pop       0.58      0.91      0.71    430965\n",
      "         rap       0.80      0.83      0.81    298959\n",
      "          rb       0.14      0.00      0.00     47343\n",
      "        rock       0.70      0.05      0.09    191812\n",
      "\n",
      "    accuracy                           0.65    994556\n",
      "   macro avg       0.44      0.36      0.32    994556\n",
      "weighted avg       0.63      0.65      0.57    994556\n",
      "\n",
      "CPU times: user 5min 38s, sys: 22.1 s, total: 6min\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & TFIDF\n",
    "tfidf_nb_report = nb_classification(df['stemmed_lyrics'], df['tag'], vectorizer='tfidf')\n",
    "print(tfidf_nb_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "im, love, like, know, dont, got, na, go, get, time\n",
      "\n",
      "Class: pop\n",
      "im, love, know, dont, like, oh, na, go, got, get\n",
      "\n",
      "Class: rap\n",
      "im, like, got, get, know, nigga, yeah, dont, fuck, bitch\n",
      "\n",
      "Class: rb\n",
      "love, know, im, yeah, dont, like, got, babi, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, time, love, go, one, come, feel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.13      0.67      0.22     25477\n",
      "         pop       0.70      0.17      0.27    430965\n",
      "         rap       0.85      0.75      0.80    298959\n",
      "          rb       0.17      0.58      0.26     47343\n",
      "        rock       0.38      0.65      0.48    191812\n",
      "\n",
      "    accuracy                           0.47    994556\n",
      "   macro avg       0.45      0.57      0.41    994556\n",
      "weighted avg       0.65      0.47      0.47    994556\n",
      "\n",
      "CPU times: user 6min 1s, sys: 25.4 s, total: 6min 26s\n",
      "Wall time: 6min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Naive Bayes & Bag of Words\n",
    "ros_bow_nb_report = nb_classification(df['stemmed_lyrics'], df['tag'], vectorizer='bow', oversample=True)\n",
    "print(ros_bow_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect RAM from garbage to prevent kernel from dying\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "lonesom, porch, whiskey, guitar, heartach, truck, tennesse, texa, hed, tailgat, cowboy, creek, bar, instrument, folk, darlin, outlaw, nashvill, counti, pine\n",
      "\n",
      "Class: pop\n",
      "fk, fcking, fck, chuckl, pre, rap, spoken, nigga, fking, evri, endless, mcs, sung, cos, refrain, fkin, sigh, diseas, total, feat\n",
      "\n",
      "Class: rap\n",
      "snippet, rapper, rap, lyric, intro, fam, opp, bro, diss, rhyme, xan, pen, mixtap, bruh, depress, tryna, shoutout, blunt, booth, glock\n",
      "\n",
      "Class: rb\n",
      "pre, outro, tryna, trynna, 2x, nigga, imma, reminisc, intro, shawti, stress, hook, homi, crib, x2, hella, finna, text, henni, mmmm\n",
      "\n",
      "Class: rock\n",
      "thе, endless, fz, diseas, punk, guitar, collaps, drag, failur, crawl, teeth, desper, total, destroy, apathi, filth, decay, despair, goddamn, wither\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.47      0.11      0.17     12677\n",
      "         pop       0.61      0.87      0.71    215359\n",
      "         rap       0.87      0.82      0.84    149486\n",
      "          rb       0.41      0.08      0.13     23802\n",
      "        rock       0.58      0.23      0.33     95954\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.59      0.42      0.44    497278\n",
      "weighted avg       0.67      0.68      0.64    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.47      0.11      0.17     12678\n",
      "         pop       0.61      0.87      0.71    215358\n",
      "         rap       0.87      0.82      0.84    149487\n",
      "          rb       0.41      0.08      0.13     23802\n",
      "        rock       0.57      0.23      0.33     95953\n",
      "\n",
      "    accuracy                           0.67    497278\n",
      "   macro avg       0.58      0.42      0.44    497278\n",
      "weighted avg       0.66      0.67      0.64    497278\n",
      "\n",
      "CPU times: user 6min 16s, sys: 1min 5s, total: 7min 22s\n",
      "Wall time: 17min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & Bag of Words\n",
    "bow_lr_test_report, bow_lr_val_report = lr_classification(df['stemmed_lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='bow',\n",
    "                                                    n_top_features=20)\n",
    "print(bow_lr_test_report, bow_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "countri, whiskey, old, truck, beer, town, cowboy, id, well, lonesom, heartach, littl, tennesse, kiss, there, aint, ol, wind, memori, texa\n",
      "\n",
      "Class: pop\n",
      "nigga, cos, repeat, pre, fcking, yo, fck, spoken, dey, bitch, flesh, club, fk, machin, colour, endless, rule, fking, hai, sea\n",
      "\n",
      "Class: rap\n",
      "rap, rapper, rhyme, li, homi, bro, gang, lyric, lil, hook, fuck, ayi, nigga, tryna, dude, bitch, mic, stress, intro, fam\n",
      "\n",
      "Class: rb\n",
      "tryna, hook, nigga, ima, vibe, bout, imma, ain, shit, shawti, pre, x2, babi, mmm, yea, bodi, bae, babe, yo, aye\n",
      "\n",
      "Class: rock\n",
      "thе, fuck, well, drag, punk, guitar, sick, goddamn, dead, blood, teeth, void, death, crawl, mouth, scream, machin, endless, diseas, kill\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.51      0.12      0.19     12677\n",
      "         pop       0.62      0.86      0.72    215359\n",
      "         rap       0.86      0.85      0.85    149486\n",
      "          rb       0.45      0.09      0.15     23802\n",
      "        rock       0.58      0.25      0.35     95954\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.60      0.43      0.45    497278\n",
      "weighted avg       0.67      0.68      0.65    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.50      0.12      0.19     12678\n",
      "         pop       0.62      0.86      0.72    215358\n",
      "         rap       0.86      0.85      0.85    149487\n",
      "          rb       0.44      0.08      0.14     23802\n",
      "        rock       0.58      0.25      0.35     95953\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.60      0.43      0.45    497278\n",
      "weighted avg       0.67      0.68      0.65    497278\n",
      "\n",
      "CPU times: user 6min 27s, sys: 1min 10s, total: 7min 38s\n",
      "Wall time: 16min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & TDIDF\n",
    "tfidf_lr_test_report, tfidf_lr_val_report = lr_classification(df['stemmed_lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    n_top_features=20)\n",
    "print(tfidf_lr_test_report, tfidf_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "truck, whiskey, beer, cowboy, countri, bar, ol, porch, tennesse, instrument, boot, texa, memri, tailgat, guitar, nashvill, counti, creek, heartach, redneck\n",
      "\n",
      "Class: pop\n",
      "nigga, cos, repeat, bitch, spoken, yo, colour, club, pre, fcking, machin, bore, fck, endless, innoc, flesh, dey, noon, nae, sigh\n",
      "\n",
      "Class: rap\n",
      "rap, rapper, tryna, rhyme, nigga, hook, li, homi, lyric, imma, mic, bro, yo, lil, shit, spit, ima, bitch, dude, ayi\n",
      "\n",
      "Class: rb\n",
      "tryna, nigga, hook, pre, imma, ima, vibe, yo, outro, stress, funki, shawti, yall, energi, bae, focus, funk, type, shit, groov\n",
      "\n",
      "Class: rock\n",
      "punk, drag, diseas, fuck, guitar, teeth, void, bore, thе, goddamn, crawl, failur, destroy, decay, machin, choke, collaps, band, sick, metal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.14      0.70      0.24     12677\n",
      "         pop       0.69      0.32      0.43    215359\n",
      "         rap       0.89      0.79      0.83    149486\n",
      "          rb       0.18      0.60      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95954\n",
      "\n",
      "    accuracy                           0.53    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.66      0.53      0.56    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.15      0.70      0.24     12678\n",
      "         pop       0.69      0.31      0.43    215358\n",
      "         rap       0.89      0.79      0.83    149487\n",
      "          rb       0.18      0.59      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95953\n",
      "\n",
      "    accuracy                           0.53    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.66      0.53      0.55    497278\n",
      "\n",
      "CPU times: user 6min 29s, sys: 42.8 s, total: 7min 12s\n",
      "Wall time: 21min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Logistic regression & TDIDF\n",
    "ros_tfidf_lr_test_report, ros_tfidf_lr_val_report = lr_classification(df['stemmed_lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    oversample=True,\n",
    "                                                    n_top_features=20)\n",
    "print(ros_tfidf_lr_test_report, ros_tfidf_lr_val_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect RAM from garbage to prevent kernel from dying\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('./pkl_files/lemmatized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>id</th>\n",
       "      <th>lyrics_word_count</th>\n",
       "      <th>lemmatized_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Killa Cam</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "      <td>1</td>\n",
       "      <td>762</td>\n",
       "      <td>[killa, cam, killa, cam, cam, killa, cam, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can I Live</td>\n",
       "      <td>rap</td>\n",
       "      <td>JAY-Z</td>\n",
       "      <td>1996</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invite, somethin,...</td>\n",
       "      <td>3</td>\n",
       "      <td>548</td>\n",
       "      <td>[yeah, hah, yeah, rocafella, invite, somethin,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forgive Me Father</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fabolous</td>\n",
       "      <td>2003</td>\n",
       "      <td>[maybe, cause, im, eatin, bastards, fiend, gru...</td>\n",
       "      <td>4</td>\n",
       "      <td>574</td>\n",
       "      <td>[maybe, cause, im, eatin, bastard, fiend, grub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Down and Out</td>\n",
       "      <td>rap</td>\n",
       "      <td>Cam'ron</td>\n",
       "      <td>2004</td>\n",
       "      <td>[ugh, killa, baby, kanye, 1970s, heron, flow, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>760</td>\n",
       "      <td>[ugh, killa, baby, kanye, 1970s, heron, flow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fly In</td>\n",
       "      <td>rap</td>\n",
       "      <td>Lil Wayne</td>\n",
       "      <td>2005</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "      <td>6</td>\n",
       "      <td>432</td>\n",
       "      <td>[ask, young, boy, gon, second, time, around, g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               title  tag     artist  year   \n",
       "0          Killa Cam  rap    Cam'ron  2004  \\\n",
       "1         Can I Live  rap      JAY-Z  1996   \n",
       "2  Forgive Me Father  rap   Fabolous  2003   \n",
       "3       Down and Out  rap    Cam'ron  2004   \n",
       "4             Fly In  rap  Lil Wayne  2005   \n",
       "\n",
       "                                              lyrics  id  lyrics_word_count   \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...   1                762  \\\n",
       "1  [yeah, hah, yeah, rocafella, invite, somethin,...   3                548   \n",
       "2  [maybe, cause, im, eatin, bastards, fiend, gru...   4                574   \n",
       "3  [ugh, killa, baby, kanye, 1970s, heron, flow, ...   5                760   \n",
       "4  [ask, young, boy, gon, second, time, around, g...   6                432   \n",
       "\n",
       "                                   lemmatized_lyrics  \n",
       "0  [killa, cam, killa, cam, cam, killa, cam, kill...  \n",
       "1  [yeah, hah, yeah, rocafella, invite, somethin,...  \n",
       "2  [maybe, cause, im, eatin, bastard, fiend, grub...  \n",
       "3  [ugh, killa, baby, kanye, 1970s, heron, flow, ...  \n",
       "4  [ask, young, boy, gon, second, time, around, g...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "im, love, like, know, dont, got, na, time, go, one\n",
      "\n",
      "Class: pop\n",
      "im, know, love, dont, like, oh, na, got, go, time\n",
      "\n",
      "Class: rap\n",
      "im, like, got, know, nigga, get, yeah, dont, bitch, shit\n",
      "\n",
      "Class: rb\n",
      "love, know, im, yeah, dont, like, got, baby, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, time, love, one, go, na, never\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.33      0.17      0.23     25477\n",
      "         pop       0.65      0.49      0.56    430965\n",
      "         rap       0.83      0.79      0.81    298959\n",
      "          rb       0.24      0.34      0.28     47343\n",
      "        rock       0.40      0.62      0.48    191812\n",
      "\n",
      "    accuracy                           0.59    994556\n",
      "   macro avg       0.49      0.48      0.47    994556\n",
      "weighted avg       0.63      0.59      0.60    994556\n",
      "\n",
      "CPU times: user 5min 37s, sys: 23.6 s, total: 6min 1s\n",
      "Wall time: 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & Bag of Words\n",
    "bow_nb_report = nb_classification(df['lemmatized_lyrics'], df['tag'], vectorizer='bow')\n",
    "print(bow_nb_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "love, im, know, dont, like, oh, time, got, one, na\n",
      "\n",
      "Class: pop\n",
      "love, im, know, dont, oh, like, na, youre, time, go\n",
      "\n",
      "Class: rap\n",
      "im, nigga, like, got, bitch, yeah, get, shit, dont, know\n",
      "\n",
      "Class: rb\n",
      "love, baby, yeah, know, im, dont, oh, na, got, like\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, time, love, youre, never, one, oh, like\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.00      0.00      0.00     25477\n",
      "         pop       0.58      0.91      0.71    430965\n",
      "         rap       0.80      0.83      0.82    298959\n",
      "          rb       0.13      0.00      0.00     47343\n",
      "        rock       0.70      0.05      0.09    191812\n",
      "\n",
      "    accuracy                           0.65    994556\n",
      "   macro avg       0.44      0.36      0.32    994556\n",
      "weighted avg       0.63      0.65      0.57    994556\n",
      "\n",
      "CPU times: user 5min 42s, sys: 32.5 s, total: 6min 14s\n",
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Naive Bayes & TFIDF\n",
    "tfidf_nb_report = nb_classification(df['lemmatized_lyrics'], df['tag'], vectorizer='tfidf')\n",
    "print(tfidf_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "im, love, like, know, dont, got, na, time, go, one\n",
      "\n",
      "Class: pop\n",
      "im, know, love, dont, like, oh, na, got, go, time\n",
      "\n",
      "Class: rap\n",
      "im, like, got, know, nigga, get, yeah, dont, bitch, shit\n",
      "\n",
      "Class: rb\n",
      "love, know, im, yeah, dont, like, got, baby, na, oh\n",
      "\n",
      "Class: rock\n",
      "im, know, dont, like, time, love, one, go, na, never\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.13      0.67      0.22     25477\n",
      "         pop       0.70      0.18      0.28    430965\n",
      "         rap       0.86      0.75      0.80    298959\n",
      "          rb       0.17      0.59      0.26     47343\n",
      "        rock       0.38      0.65      0.48    191812\n",
      "\n",
      "    accuracy                           0.47    994556\n",
      "   macro avg       0.45      0.57      0.41    994556\n",
      "weighted avg       0.65      0.47      0.47    994556\n",
      "\n",
      "CPU times: user 6min 1s, sys: 32.6 s, total: 6min 34s\n",
      "Wall time: 6min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Naive Bayes & Bag of Words\n",
    "ros_bow_nb_report = nb_classification(df['lemmatized_lyrics'], df['tag'], vectorizer='bow', oversample=True)\n",
    "print(ros_bow_nb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect RAM from garbage to prevent kernel from dying\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "lonesome, porch, whiskey, guitar, heartache, truck, tennessee, texas, tailgate, hed, instrumental, cowboy, creek, headed, folk, outlaw, nashville, darlin, bar, jukebox\n",
      "\n",
      "Class: pop\n",
      "fcking, fk, rap, chuckle, fck, pre, fking, spoken, nigga, evry, endless, mc, sung, fkin, disease, refrain, co, feat, noone, yourll\n",
      "\n",
      "Class: rap\n",
      "snippet, rapping, rapper, lyric, rap, intro, fam, spitting, depression, opps, hook, booth, bro, bruh, pen, glock, shoutout, tryna, rhyme, mixtape\n",
      "\n",
      "Class: rb\n",
      "pre, outro, tryna, trynna, 2x, hook, nigga, imma, intro, shawty, focused, crib, finna, hella, henny, stress, hoe, mmmm, x2, tho\n",
      "\n",
      "Class: rock\n",
      "thе, endless, fz, disease, guitar, punk, failure, decay, drag, collapse, teeth, filth, apathy, despair, fucking, destroy, desperate, noose, crawling, dragged\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.47      0.11      0.18     12677\n",
      "         pop       0.61      0.87      0.71    215359\n",
      "         rap       0.87      0.82      0.85    149486\n",
      "          rb       0.41      0.08      0.14     23802\n",
      "        rock       0.58      0.24      0.34     95954\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.59      0.43      0.44    497278\n",
      "weighted avg       0.67      0.68      0.64    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.47      0.11      0.18     12678\n",
      "         pop       0.61      0.87      0.71    215358\n",
      "         rap       0.87      0.82      0.85    149487\n",
      "          rb       0.41      0.08      0.14     23802\n",
      "        rock       0.57      0.24      0.34     95953\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.58      0.42      0.44    497278\n",
      "weighted avg       0.67      0.68      0.64    497278\n",
      "\n",
      "CPU times: user 5min 45s, sys: 26.5 s, total: 6min 12s\n",
      "Wall time: 15min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & Bag of Words\n",
    "bow_lr_test_report, bow_lr_val_report = lr_classification(df['lemmatized_lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='bow',\n",
    "                                                    n_top_features=20)\n",
    "print(bow_lr_test_report, bow_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "whiskey, country, truck, beer, cowboy, old, town, id, heartache, lonesome, tennessee, wind, ol, well, bar, texas, kiss, memory, boot, guitar\n",
      "\n",
      "Class: pop\n",
      "nigga, fcking, repeat, pre, fck, yo, co, dey, spoken, fk, club, machine, flesh, fking, well, endless, hai, noone, tv, colour\n",
      "\n",
      "Class: rap\n",
      "rap, rapper, rhyme, nigga, li, hook, bro, gang, lil, bitch, tryna, homie, rapping, dude, lyric, mic, ayy, intro, fam, flow\n",
      "\n",
      "Class: rb\n",
      "tryna, hook, ima, nigga, imma, pre, vibe, shit, x2, shawty, bout, ain, mmm, yea, yo, bae, joy, aye, body, energy\n",
      "\n",
      "Class: rock\n",
      "thе, fucking, well, punk, guitar, sick, drag, goddamn, death, blood, teeth, dead, machine, void, endless, disease, mouth, anyway, everyone, scream\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.51      0.13      0.21     12677\n",
      "         pop       0.62      0.85      0.72    215359\n",
      "         rap       0.86      0.85      0.85    149486\n",
      "          rb       0.46      0.09      0.15     23802\n",
      "        rock       0.57      0.27      0.37     95954\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.61      0.44      0.46    497278\n",
      "weighted avg       0.67      0.68      0.65    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.49      0.13      0.21     12678\n",
      "         pop       0.62      0.85      0.72    215358\n",
      "         rap       0.86      0.85      0.85    149487\n",
      "          rb       0.45      0.09      0.15     23802\n",
      "        rock       0.57      0.27      0.36     95953\n",
      "\n",
      "    accuracy                           0.68    497278\n",
      "   macro avg       0.60      0.44      0.46    497278\n",
      "weighted avg       0.67      0.68      0.65    497278\n",
      "\n",
      "CPU times: user 5min 49s, sys: 34.6 s, total: 6min 24s\n",
      "Wall time: 15min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Logistic regression & TDIDF\n",
    "tfidf_lr_test_report, tfidf_lr_val_report = lr_classification(df['lemmatized_lyrics'], df['tag'],\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    n_top_features=20)\n",
    "print(tfidf_lr_test_report, tfidf_lr_val_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: country\n",
      "truck, whiskey, country, beer, cowboy, bar, ol, tennessee, old, boots, porch, heartaches, texas, instrumental, lonesome, tailgate, county, guitar, honky, town\n",
      "\n",
      "Class: pop\n",
      "cos, repeat, spoken, yo, pre, bitch, fcking, endless, club, noone, flesh, fck, dey, nae, machine, sea, youve, tv, colour, ga\n",
      "\n",
      "Class: rap\n",
      "rap, tryna, hook, nigga, niggas, rappers, rhymes, li, shit, yo, mic, bro, imma, flow, homie, rapper, bars, lyrics, rapping, lil\n",
      "\n",
      "Class: rb\n",
      "tryna, hook, pre, niggas, imma, nigga, ima, vibe, yo, shit, outro, shawty, funky, bae, energy, yall, x2, bout, type, funk\n",
      "\n",
      "Class: rock\n",
      "disease, fucking, band, void, teeth, punk, well, drag, destroy, sick, machine, decay, scream, crawling, metal, endless, thе, goddamn, guitar, lungs\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     country       0.15      0.69      0.24     12677\n",
      "         pop       0.69      0.32      0.44    215359\n",
      "         rap       0.89      0.79      0.83    149486\n",
      "          rb       0.19      0.59      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95954\n",
      "\n",
      "    accuracy                           0.54    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.67      0.54      0.56    497278\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     country       0.15      0.70      0.25     12678\n",
      "         pop       0.69      0.32      0.44    215358\n",
      "         rap       0.89      0.79      0.83    149487\n",
      "          rb       0.19      0.59      0.28     23802\n",
      "        rock       0.44      0.59      0.50     95953\n",
      "\n",
      "    accuracy                           0.54    497278\n",
      "   macro avg       0.47      0.60      0.46    497278\n",
      "weighted avg       0.67      0.54      0.56    497278\n",
      "\n",
      "CPU times: user 6min 7s, sys: 38.1 s, total: 6min 45s\n",
      "Wall time: 21min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Random Oversampling with Logistic regression & TDIDF\n",
    "ros_tfidf_lr_test_report, ros_tfidf_lr_val_report = lr_classification(df['lyrics'], df['tag'],\n",
    "                                                    oversample=True,\n",
    "                                                    vectorizer_method='tdidf',\n",
    "                                                    n_top_features=20)\n",
    "print(ros_tfidf_lr_test_report, ros_tfidf_lr_val_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
